{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe66e455",
   "metadata": {},
   "source": [
    "# (09) Neural analysis (KABA)\n",
    "\n",
    "**Motivation**: <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccc224d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "\n",
    "import os, sys\n",
    "from IPython.display import display\n",
    "\n",
    "# tmp & extras dir\n",
    "git_dir = os.path.join(os.environ['HOME'], 'Dropbox/git')\n",
    "extras_dir = os.path.join(git_dir, 'jb-MTMST/_extras')\n",
    "fig_base_dir = os.path.join(git_dir, 'jb-MTMST/figs')\n",
    "tmp_dir = os.path.join(git_dir, 'jb-MTMST/tmp')\n",
    "\n",
    "# GitHub\n",
    "sys.path.insert(0, os.path.join(git_dir, '_MTMST'))\n",
    "from vae.train_vae import TrainerVAE, ConfigTrainVAE\n",
    "from vae.vae2d import VAE, ConfigVAE\n",
    "from figures.fighelper import *\n",
    "from analysis.glm import *\n",
    "\n",
    "\n",
    "# warnings, tqdm, & style\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from rich.jupyter import print\n",
    "%matplotlib inline\n",
    "set_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592efcb2",
   "metadata": {},
   "source": [
    "## Trainer paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc9911e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = results_dir()\n",
    "path = pathlib.Path(path)\n",
    "\n",
    "trainer_paths = set()\n",
    "pat = '**/Trainer' # '**/*fixate1*/**/Trainer'\n",
    "for p in path.rglob(pat):\n",
    "    if p.is_dir():\n",
    "        trainer_paths.add(str(p))\n",
    "trainer_paths = sorted(trainer_paths)\n",
    "len(trainer_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31615af4",
   "metadata": {},
   "source": [
    "### Select a subset of fitted models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a92c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which_sims = [\n",
    "    'obj1',\n",
    "    'fixate0', 'fixate1', 'fixate2',\n",
    "    'transl0', 'transl1', 'transl2',\n",
    "]\n",
    "which_nf = [280, 420]\n",
    "\n",
    "selected_fits = []\n",
    "for fit_path in trainer_paths:\n",
    "    fit_name = fit_path.split('/')[-2]\n",
    "    info = fit_name.split('_')\n",
    "    i = info.index([\n",
    "        e for e in info\n",
    "        if 'nf-' in e\n",
    "    ].pop())\n",
    "    nf = int(info[i].split('-')[1])\n",
    "    cond = (\n",
    "        nf not in which_nf or\n",
    "        not any(e in fit_name for e in which_sims)\n",
    "    )\n",
    "    if cond:\n",
    "        continue\n",
    "    else:\n",
    "        selected_fits.append(fit_path)\n",
    "len(selected_fits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ea80f",
   "metadata": {},
   "source": [
    "### Select main ground truth variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4437412",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_main = [\n",
    "    'fix_x',\n",
    "    'fix_y',\n",
    "    'slf_v_x',\n",
    "    'slf_v_y',\n",
    "    'slf_v_z',\n",
    "    'obj0_x',\n",
    "    'obj0_y',\n",
    "    'obj0_z',\n",
    "    'obj0_v_x',\n",
    "    'obj0_v_y',\n",
    "    'obj0_v_z',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d6aa2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fit_path in selected_fits:\n",
    "    fit_name = fit_path.split('/')[-2]\n",
    "    f = pjoin(tmp_dir, 'neural_analysis', f\"{fit_name}.npy\")\n",
    "    if not os.path.isfile(f):\n",
    "        print(fit_name, os.path.isfile(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbb1d6e",
   "metadata": {},
   "source": [
    "## Neural results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "430692e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 21236.98it/s]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(selected_fits)\n",
    "for fit_path in pbar:\n",
    "    fit_name = fit_path.split('/')[-2]\n",
    "    f = pjoin(tmp_dir, 'neural_analysis', f\"{fit_name}.npy\")\n",
    "    if os.path.isfile(f):\n",
    "        continue\n",
    "    pbar.set_description(fit_name)\n",
    "    \n",
    "    f = pjoin(tmp_dir, 'trainer_analysis', fit_name)\n",
    "    f = f\"{f}.npy\"\n",
    "    if os.path.isfile(f):\n",
    "        everything = np.load(f, allow_pickle=True).item()\n",
    "    else:\n",
    "        print(f\"not found: {fit_name}\")\n",
    "        continue\n",
    "\n",
    "    df, df_all, ro_all, args, tr = summarize_neural_fits(\n",
    "        fit_name=fit_name, device='cuda:1')\n",
    "\n",
    "    labels = tr.dl_trn.dataset.f + tr.dl_trn.dataset.f_aux\n",
    "    selected = [\n",
    "        i for i, lbl in\n",
    "        enumerate(labels)\n",
    "        if lbl in labels_main\n",
    "    ]\n",
    "    \n",
    "    # extract neural results\n",
    "    neural_results = collections.defaultdict(dict)\n",
    "    for key, ro in ro_all.items():\n",
    "        for cell, m in ro.mod.items():\n",
    "            data = ro.validate(cell)\n",
    "            pred = m.predict(data['x'])\n",
    "            if ro.has_repeats:\n",
    "                pred_tst = m.predict(data['x_tst'])\n",
    "            else:\n",
    "                pred_tst = None\n",
    "\n",
    "            # STA (model)\n",
    "            sta_model = compute_sta(\n",
    "                n_lags=0,\n",
    "                stim=ro.stim[ro.good],\n",
    "                spks=pred.reshape(-1, 1),\n",
    "            ).squeeze()\n",
    "\n",
    "            # STA\n",
    "            lag = ro.best_lag[cell]\n",
    "            inds = ro.good.copy()\n",
    "            inds = inds[inds > lag]\n",
    "            inds = inds - lag\n",
    "            sta_spks = compute_sta(\n",
    "                n_lags=0,\n",
    "                stim=ro.stim[inds],\n",
    "                spks=data['y'].reshape(-1, 1),\n",
    "            ).squeeze()\n",
    "\n",
    "            # perm importance\n",
    "            perm = sk_inspect.permutation_importance(\n",
    "                estimator=m,\n",
    "                X=data['x_tst' if ro.has_repeats else 'x'],\n",
    "                y=data['y_tst' if ro.has_repeats else 'y'],\n",
    "                random_state=0,\n",
    "                n_repeats=10,\n",
    "            )\n",
    "            perm_mu = np.maximum(0, perm['importances_mean'])\n",
    "            perm_sd = perm['importances_std']\n",
    "\n",
    "            # Probs\n",
    "            p_z_given_neuron = perm_mu / perm_mu.sum()\n",
    "            a = 1 - entropy_normalized(p_z_given_neuron, axis=0)\n",
    "            p_g_given_z = np.maximum(0, everything['importances_mu'])[selected]\n",
    "            p_g_given_z = p_g_given_z / p_g_given_z.sum(0, keepdims=True)\n",
    "            p_g_given_neuron = p_g_given_z @ p_z_given_neuron\n",
    "\n",
    "            k = f\"{key}_{cell}\"\n",
    "            neural_results['data'][k] = data\n",
    "            neural_results['pred'][k] = pred\n",
    "            neural_results['pred_tst'][k] = pred_tst\n",
    "            neural_results['sta_model'][k] = sta_model\n",
    "            neural_results['sta_spks'][k] = sta_spks\n",
    "            neural_results['perm_mu'][k] = perm_mu\n",
    "            neural_results['perm_sd'][k] = perm_sd\n",
    "            neural_results['alignment_score'][k] = a\n",
    "            neural_results['p_g_given_z'][k] = p_g_given_z\n",
    "            neural_results['p_z_given_neuron'][k] = p_z_given_neuron\n",
    "            neural_results['p_g_given_neuron'][k] = p_g_given_neuron\n",
    "            neural_results['labels'][k] = list(np.array(labels)[selected])\n",
    "\n",
    "    # save\n",
    "    save_obj(\n",
    "        obj=neural_results,\n",
    "        file_name=fit_name,\n",
    "        save_dir=pjoin(tmp_dir, 'neural_analysis'),\n",
    "        verbose=True,\n",
    "        mode='npy',\n",
    "    )\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad1f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a69e78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fit_path in selected_fits:\n",
    "    fit_name = fit_path.split('/')[-2]\n",
    "    f = pjoin(tmp_dir, 'neural_analysis', f\"{fit_name}.npy\")\n",
    "    if not os.path.isfile(f):\n",
    "        print(fit_name, os.path.isfile(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb439b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea67fe83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfc4180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
