{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9736f88",
   "metadata": {},
   "source": [
    "# (04) PyTorch profiler\n",
    "\n",
    "**Motivation**: @torch.jit.script was slowing things down <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5360bb70",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "\n",
    "import os, sys\n",
    "from IPython.display import display\n",
    "\n",
    "# tmp & extras dir\n",
    "git_dir = os.path.join(os.environ['HOME'], 'Dropbox/git')\n",
    "extras_dir = os.path.join(git_dir, 'jb-MTMST/_extras')\n",
    "fig_base_dir = os.path.join(git_dir, 'jb-MTMST/figs')\n",
    "tmp_dir = os.path.join(git_dir, 'jb-MTMST/tmp')\n",
    "\n",
    "# GitHub\n",
    "sys.path.insert(0, os.path.join(git_dir, '_MTMST'))\n",
    "from model.train_vae import TrainerVAE, ConfigTrainVAE\n",
    "from model.vae2d import VAE, ConfigVAE\n",
    "from analysis.opticflow import *\n",
    "from figures.fighelper import *\n",
    "\n",
    "# warnings, tqdm, & style\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from tqdm.notebook import tqdm\n",
    "from rich.jupyter import print\n",
    "%matplotlib inline\n",
    "set_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f199f8a7",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2648828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE(ConfigVAE(\n",
    "    n_latent_scales=2, n_groups_per_scale=20, n_latent_per_group=7,\n",
    "    scale_init=False, residual_kl=True, ada_groups=True, # separable=False,\n",
    "))\n",
    "self = TrainerVAE(\n",
    "    model=vae,\n",
    "    cfg=ConfigTrainVAE(\n",
    "        lr=0.002, batch_size=500, epochs=2000, grad_clip=None,\n",
    "        lambda_anneal=True, lambda_init=1e-7, lambda_norm=1e-2,\n",
    "        kl_beta=0.25, kl_anneal_cycles=1, \n",
    "        scheduler_kws={'T_max': 660.0, 'eta_min': 1e-05},   \n",
    "        optimizer='adamax_fast',\n",
    "    ),\n",
    "    device='cuda:1',\n",
    ")\n",
    "vae.cfg.total_latents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41b0547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">+--------------+------------+\n",
       "| Module Name  | Num Params |\n",
       "+--------------+------------+\n",
       "|     VAE      |  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17.0</span> Mil  |\n",
       "|     ---      |    ---     |\n",
       "|     stem     |   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1</span> K    |\n",
       "| pre_process  |   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96.0</span> K   |\n",
       "|  enc_tower   |  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.4</span> Mil   |\n",
       "|     enc0     |   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.6</span> K   |\n",
       "| enc_sampler  |  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4</span> Mil   |\n",
       "| dec_sampler  |  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4</span> Mil   |\n",
       "|    expand    |   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71.0</span> K   |\n",
       "|  dec_tower   |  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.5</span> Mil   |\n",
       "| post_process |   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40.0</span> K   |\n",
       "|     out      |    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">578</span>     |\n",
       "+--------------+------------+ \n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "+--------------+------------+\n",
       "| Module Name  | Num Params |\n",
       "+--------------+------------+\n",
       "|     VAE      |  \u001b[1;36m17.0\u001b[0m Mil  |\n",
       "|     ---      |    ---     |\n",
       "|     stem     |   \u001b[1;36m1.1\u001b[0m K    |\n",
       "| pre_process  |   \u001b[1;36m96.0\u001b[0m K   |\n",
       "|  enc_tower   |  \u001b[1;36m9.4\u001b[0m Mil   |\n",
       "|     enc0     |   \u001b[1;36m16.6\u001b[0m K   |\n",
       "| enc_sampler  |  \u001b[1;36m1.4\u001b[0m Mil   |\n",
       "| dec_sampler  |  \u001b[1;36m1.4\u001b[0m Mil   |\n",
       "|    expand    |   \u001b[1;36m71.0\u001b[0m K   |\n",
       "|  dec_tower   |  \u001b[1;36m4.5\u001b[0m Mil   |\n",
       "| post_process |   \u001b[1;36m40.0\u001b[0m K   |\n",
       "|     out      |    \u001b[1;36m578\u001b[0m     |\n",
       "+--------------+------------+ \n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[8, 4]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.print()\n",
    "vae.scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2627dee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291, 287)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vae.all_conv_layers), len(vae.all_log_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293128cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f46a70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79610f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neither epe, nor _normalize have jit. furthermore, _normalize uses linalg.vector_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0249a277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch # 100, avg loss: 4.861284: 100%|██████████| 100/100 [1:49:38<00:00, 65.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 47min 2s, sys: 3min 38s, total: 1h 50min 41s\n",
      "Wall time: 1h 49min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "self.train(100, 'test', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd9a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6e68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e0808c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7137bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:18<00:00,  4.25it/s]\n",
      "100%|██████████| 80/80 [00:16<00:00,  4.93it/s]\n",
      "100%|██████████| 80/80 [00:17<00:00,  4.71it/s]\n",
      "100%|██████████| 80/80 [00:14<00:00,  5.49it/s]\n",
      "100%|██████████| 80/80 [00:14<00:00,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 21s, sys: 1.53 s, total: 1min 22s\n",
      "Wall time: 1min 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "self.model.train()\n",
    "\n",
    "for _ in range(5):\n",
    "    for x, norm in tqdm(iter(self.dl_trn)):\n",
    "        self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ad4b7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:21<00:00,  3.81it/s]\n",
      "100%|██████████| 80/80 [00:15<00:00,  5.09it/s]\n",
      "100%|██████████| 80/80 [00:17<00:00,  4.57it/s]\n",
      "100%|██████████| 80/80 [00:14<00:00,  5.35it/s]\n",
      "100%|██████████| 80/80 [00:15<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 1.65 s, total: 1min 27s\n",
      "Wall time: 1min 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# was with bunch of jit at Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d9ae067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:14<00:00,  5.57it/s]\n",
      "100%|██████████| 80/80 [00:13<00:00,  6.07it/s]\n",
      "100%|██████████| 80/80 [00:11<00:00,  6.92it/s]\n",
      "100%|██████████| 80/80 [00:12<00:00,  6.27it/s]\n",
      "100%|██████████| 80/80 [00:11<00:00,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 1.64 s, total: 1min 6s\n",
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# was with torch.linalg.vector_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943609bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "864c4c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.utils_model import kl_balancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abf78811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "self.pbar = tqdm(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63810a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gstep # 61, nelbo: 15.907, grad: 228.0:   0%|          | 0/10 [05:06<?, ?it/s]      "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/Dropbox/git/_MTMST/model/train_vae.py:84\u001b[0m, in \u001b[0;36mTrainerVAE.iteration\u001b[0;34m(self, epoch, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# forward + loss\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_amp):\n\u001b[0;32m---> 84\u001b[0m \ty, _, q, p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \tepe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mloss_recon(x\u001b[38;5;241m=\u001b[39mx, y\u001b[38;5;241m=\u001b[39my, w\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mnorm)\n\u001b[1;32m     86\u001b[0m \tkl_all, kl_diag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mloss_kl(q, p)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for e in range(5): \n",
    "    self.iteration(0, n_iters_warmup=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b458e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:54,  1.48it/s]\n",
      "80it [00:43,  1.84it/s]\n",
      "80it [00:44,  1.78it/s]\n",
      "80it [00:48,  1.65it/s]\n",
      "80it [00:44,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 51s, sys: 6.77 s, total: 3min 58s\n",
      "Wall time: 3min 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "self.model.train()\n",
    "\n",
    "for e in range(5): \n",
    "    for i, (x, norm) in tqdm(enumerate(iter(self.dl_trn))):\n",
    "        gstep = e * len(self.dl_trn) + i\n",
    "        y, _, q, p = self.model(x)\n",
    "        epe = self.model.loss_recon(x=x, y=y, w=1/norm)\n",
    "        kl_all, kl_diag = self.model.loss_kl(q, p)\n",
    "        # balance kl\n",
    "        balanced_kl, gamma, kl_vals = kl_balancer(\n",
    "            kl_all=kl_all,\n",
    "            alpha=self.alphas,\n",
    "            coeff=self.betas[gstep],\n",
    "            beta=self.cfg.kl_beta,\n",
    "        )\n",
    "        loss = torch.mean(epe + balanced_kl)\n",
    "        # add regularization\n",
    "        loss_w = self.model.loss_weight()\n",
    "        if self.wd_coeffs[gstep] > 0:\n",
    "            loss += self.wd_coeffs[gstep] * loss_w\n",
    "        cond_reg_spectral = self.cfg.lambda_norm > 0 \\\n",
    "            and self.cfg.spectral_reg and \\\n",
    "            not self.model.cfg.spectral_norm\n",
    "        if cond_reg_spectral:\n",
    "            loss_sr = self.model.loss_spectral(\n",
    "                device=self.device, name='w')\n",
    "            loss += self.wd_coeffs[gstep] * loss_sr\n",
    "        else:\n",
    "            loss_sr = None\n",
    "        loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "779ab089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:51,  1.54it/s]\n",
      "80it [00:46,  1.72it/s]\n",
      "80it [00:42,  1.88it/s]\n",
      "80it [00:46,  1.73it/s]\n",
      "80it [00:48,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 50s, sys: 8.81 s, total: 3min 59s\n",
      "Wall time: 3min 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# was with torch.linalg.vector_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8ca1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ffae1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [\n",
    "    torch.profiler.ProfilerActivity.CPU,\n",
    "    torch.profiler.ProfilerActivity.CUDA,\n",
    "]\n",
    "kws = dict(\n",
    "    activities=activities,\n",
    "    record_shapes=True,\n",
    "    with_stack=True,\n",
    ")\n",
    "with torch.profiler.profile(**kws) as prof:\n",
    "    y, _, q, p = self.model(x)\n",
    "    epe = self.model.loss_recon(x=x, y=y, w=1/norm)\n",
    "    kl_all, kl_diag = self.model.loss_kl(q, p)\n",
    "    # balance kl\n",
    "    balanced_kl, gamma, kl_vals = kl_balancer(\n",
    "        kl_all=kl_all,\n",
    "        alpha=self.alphas,\n",
    "        coeff=self.betas[gstep],\n",
    "        beta=self.cfg.kl_beta,\n",
    "    )\n",
    "    loss = torch.mean(epe + balanced_kl)\n",
    "    # add regularization\n",
    "    loss_w = self.model.loss_weight()\n",
    "    if self.wd_coeffs[gstep] > 0:\n",
    "        loss += self.wd_coeffs[gstep] * loss_w\n",
    "    cond_reg_spectral = self.cfg.lambda_norm > 0 \\\n",
    "        and self.cfg.spectral_reg and \\\n",
    "        not self.model.cfg.spectral_norm\n",
    "    if cond_reg_spectral:\n",
    "        loss_sr = self.model.loss_spectral(\n",
    "            device=self.device, name='w')\n",
    "        loss += self.wd_coeffs[gstep] * loss_sr\n",
    "    else:\n",
    "        loss_sr = None\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df7b5561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-------------------------------------------------------  ------------  ------------  \n",
       "------------  ------------  ------------  ------------  ------------  ------------  \n",
       "------------  ------------  \n",
       "                                                   Name    Self CPU %      Self CPU   CPU \n",
       "total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg \n",
       "# of Calls  \n",
       "-------------------------------------------------------  ------------  ------------  \n",
       "------------  ------------  ------------  ------------  ------------  ------------  \n",
       "------------  ------------  \n",
       "                             aten::convolution_backward         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.90</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56.</span>383ms        \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.40</span>%     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">108.</span>907ms     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">310.</span>276us     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">208.</span>844ms        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49.17</span>%     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">218.</span>653ms     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">622.</span>943us   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">351</span>  \n",
       "                                aten::cudnn_convolution         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.00</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.</span>745ms         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.45</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71.</span>201ms     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">221.</span>810us      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71.</span>497ms        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.83</span>%     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">105.</span>171ms     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">327.</span>636us    \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">321</span>  \n",
       "void cudnn::detail::dgrad_alg1_engine&lt;float, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,<span style=\"color: #808000; text-decoration-color: #808000\">...</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>%       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>000us         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>%       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>000us       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>000us      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63.</span>215ms        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.88</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63.</span>215ms       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.</span>054ms    \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span>  \n",
       "                                   volta_sgemm_64x64_nt         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>%       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>000us         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>%       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>000us       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>000us      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46.</span>713ms        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.00</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46.</span>713ms     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">126.</span>593us    \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">369</span>  \n",
       "                                       cudaLaunchKernel        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.61</span>%     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">254.</span>222ms        \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.61</span>%     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">254.</span>222ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.</span>282us      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43.</span>567ms        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.26</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43.</span>567ms       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.</span>790us   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15614</span>  \n",
       "                                             aten::add_         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.54</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33.</span>856ms         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.90</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">65.</span>932ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.</span>205us      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32.</span>449ms         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.64</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34.</span>505ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.</span>714us    \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2516</span>  \n",
       "void at::native::vectorized_elementwise_kernel&lt;<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, at<span style=\"color: #808000; text-decoration-color: #808000\">...</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>%       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>000us         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>%       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>000us       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>000us      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31.</span>880ms         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.51</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31.</span>880ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12.</span>468us    \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2557</span>  \n",
       "void cudnn::winograd_nonfused::winogradForwardData4x<span style=\"color: #808000; text-decoration-color: #808000\">...</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>%       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>000us         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>%       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>000us       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>000us      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31.</span>435ms         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.40</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31.</span>435ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85.</span>190us    \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">369</span>  \n",
       "void cudnn::winograd_nonfused::winogradForwardOutput<span style=\"color: #808000; text-decoration-color: #808000\">...</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>%       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>000us         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>%       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>000us       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>000us      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.</span>804ms         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.31</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.</span>804ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72.</span>640us    \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">369</span>  \n",
       "                                              aten::mul         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.81</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55.</span>523ms         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.15</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">87.</span>372ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37.</span>725us      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21.</span>854ms         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.15</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.</span>911ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.</span>620us    \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2316</span>  \n",
       "-------------------------------------------------------  ------------  ------------  \n",
       "------------  ------------  ------------  ------------  ------------  ------------  \n",
       "------------  ------------  \n",
       "Self CPU time total: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">955.</span>230ms\n",
       "Self CUDA time total: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">424.</span>738ms\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "-------------------------------------------------------  ------------  ------------  \n",
       "------------  ------------  ------------  ------------  ------------  ------------  \n",
       "------------  ------------  \n",
       "                                                   Name    Self CPU %      Self CPU   CPU \n",
       "total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg \n",
       "# of Calls  \n",
       "-------------------------------------------------------  ------------  ------------  \n",
       "------------  ------------  ------------  ------------  ------------  ------------  \n",
       "------------  ------------  \n",
       "                             aten::convolution_backward         \u001b[1;36m5.90\u001b[0m%      \u001b[1;36m56.\u001b[0m383ms        \n",
       "\u001b[1;36m11.40\u001b[0m%     \u001b[1;36m108.\u001b[0m907ms     \u001b[1;36m310.\u001b[0m276us     \u001b[1;36m208.\u001b[0m844ms        \u001b[1;36m49.17\u001b[0m%     \u001b[1;36m218.\u001b[0m653ms     \u001b[1;36m622.\u001b[0m943us   \n",
       "\u001b[1;36m351\u001b[0m  \n",
       "                                aten::cudnn_convolution         \u001b[1;36m5.00\u001b[0m%      \u001b[1;36m47.\u001b[0m745ms         \n",
       "\u001b[1;36m7.45\u001b[0m%      \u001b[1;36m71.\u001b[0m201ms     \u001b[1;36m221.\u001b[0m810us      \u001b[1;36m71.\u001b[0m497ms        \u001b[1;36m16.83\u001b[0m%     \u001b[1;36m105.\u001b[0m171ms     \u001b[1;36m327.\u001b[0m636us    \n",
       "\u001b[1;36m321\u001b[0m  \n",
       "void cudnn::detail::dgrad_alg1_engine<float, \u001b[1;36m128\u001b[0m, \u001b[1;36m6\u001b[0m,\u001b[33m...\u001b[0m         \u001b[1;36m0.00\u001b[0m%       \u001b[1;36m0.\u001b[0m000us         \n",
       "\u001b[1;36m0.00\u001b[0m%       \u001b[1;36m0.\u001b[0m000us       \u001b[1;36m0.\u001b[0m000us      \u001b[1;36m63.\u001b[0m215ms        \u001b[1;36m14.88\u001b[0m%      \u001b[1;36m63.\u001b[0m215ms       \u001b[1;36m1.\u001b[0m054ms    \n",
       "\u001b[1;36m60\u001b[0m  \n",
       "                                   volta_sgemm_64x64_nt         \u001b[1;36m0.00\u001b[0m%       \u001b[1;36m0.\u001b[0m000us         \n",
       "\u001b[1;36m0.00\u001b[0m%       \u001b[1;36m0.\u001b[0m000us       \u001b[1;36m0.\u001b[0m000us      \u001b[1;36m46.\u001b[0m713ms        \u001b[1;36m11.00\u001b[0m%      \u001b[1;36m46.\u001b[0m713ms     \u001b[1;36m126.\u001b[0m593us    \n",
       "\u001b[1;36m369\u001b[0m  \n",
       "                                       cudaLaunchKernel        \u001b[1;36m26.61\u001b[0m%     \u001b[1;36m254.\u001b[0m222ms        \n",
       "\u001b[1;36m26.61\u001b[0m%     \u001b[1;36m254.\u001b[0m222ms      \u001b[1;36m16.\u001b[0m282us      \u001b[1;36m43.\u001b[0m567ms        \u001b[1;36m10.26\u001b[0m%      \u001b[1;36m43.\u001b[0m567ms       \u001b[1;36m2.\u001b[0m790us   \n",
       "\u001b[1;36m15614\u001b[0m  \n",
       "                                             aten::add_         \u001b[1;36m3.54\u001b[0m%      \u001b[1;36m33.\u001b[0m856ms         \n",
       "\u001b[1;36m6.90\u001b[0m%      \u001b[1;36m65.\u001b[0m932ms      \u001b[1;36m26.\u001b[0m205us      \u001b[1;36m32.\u001b[0m449ms         \u001b[1;36m7.64\u001b[0m%      \u001b[1;36m34.\u001b[0m505ms      \u001b[1;36m13.\u001b[0m714us    \n",
       "\u001b[1;36m2516\u001b[0m  \n",
       "void at::native::vectorized_elementwise_kernel<\u001b[1;36m4\u001b[0m, at\u001b[33m...\u001b[0m         \u001b[1;36m0.00\u001b[0m%       \u001b[1;36m0.\u001b[0m000us         \n",
       "\u001b[1;36m0.00\u001b[0m%       \u001b[1;36m0.\u001b[0m000us       \u001b[1;36m0.\u001b[0m000us      \u001b[1;36m31.\u001b[0m880ms         \u001b[1;36m7.51\u001b[0m%      \u001b[1;36m31.\u001b[0m880ms      \u001b[1;36m12.\u001b[0m468us    \n",
       "\u001b[1;36m2557\u001b[0m  \n",
       "void cudnn::winograd_nonfused::winogradForwardData4x\u001b[33m...\u001b[0m         \u001b[1;36m0.00\u001b[0m%       \u001b[1;36m0.\u001b[0m000us         \n",
       "\u001b[1;36m0.00\u001b[0m%       \u001b[1;36m0.\u001b[0m000us       \u001b[1;36m0.\u001b[0m000us      \u001b[1;36m31.\u001b[0m435ms         \u001b[1;36m7.40\u001b[0m%      \u001b[1;36m31.\u001b[0m435ms      \u001b[1;36m85.\u001b[0m190us    \n",
       "\u001b[1;36m369\u001b[0m  \n",
       "void cudnn::winograd_nonfused::winogradForwardOutput\u001b[33m...\u001b[0m         \u001b[1;36m0.00\u001b[0m%       \u001b[1;36m0.\u001b[0m000us         \n",
       "\u001b[1;36m0.00\u001b[0m%       \u001b[1;36m0.\u001b[0m000us       \u001b[1;36m0.\u001b[0m000us      \u001b[1;36m26.\u001b[0m804ms         \u001b[1;36m6.31\u001b[0m%      \u001b[1;36m26.\u001b[0m804ms      \u001b[1;36m72.\u001b[0m640us    \n",
       "\u001b[1;36m369\u001b[0m  \n",
       "                                              aten::mul         \u001b[1;36m5.81\u001b[0m%      \u001b[1;36m55.\u001b[0m523ms         \n",
       "\u001b[1;36m9.15\u001b[0m%      \u001b[1;36m87.\u001b[0m372ms      \u001b[1;36m37.\u001b[0m725us      \u001b[1;36m21.\u001b[0m854ms         \u001b[1;36m5.15\u001b[0m%      \u001b[1;36m26.\u001b[0m911ms      \u001b[1;36m11.\u001b[0m620us    \n",
       "\u001b[1;36m2316\u001b[0m  \n",
       "-------------------------------------------------------  ------------  ------------  \n",
       "------------  ------------  ------------  ------------  ------------  ------------  \n",
       "------------  ------------  \n",
       "Self CPU time total: \u001b[1;36m955.\u001b[0m230ms\n",
       "Self CUDA time total: \u001b[1;36m424.\u001b[0m738ms\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a94b9168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-------------------------------------------------------  ------------  ------------  \n",
       "------------  ------------  ------------  ------------  ------------  ------------  \n",
       "------------  ------------  \n",
       "                                                   Name    Self CPU %      Self CPU   CPU \n",
       "total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg \n",
       "# of Calls  \n",
       "-------------------------------------------------------  ------------  ------------  \n",
       "------------  ------------  ------------  ------------  ------------  ------------  \n",
       "------------  ------------  \n",
       "                                       cudaLaunchKernel        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.61</span>%     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">254.</span>222ms        \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.61</span>%     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">254.</span>222ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.</span>282us      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43.</span>567ms        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.26</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43.</span>567ms       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.</span>790us   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15614</span>  \n",
       "                             aten::convolution_backward         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.90</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56.</span>383ms        \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.40</span>%     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">108.</span>907ms     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">310.</span>276us     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">208.</span>844ms        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49.17</span>%     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">218.</span>653ms     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">622.</span>943us   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">351</span>  \n",
       "                                              aten::mul         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.81</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55.</span>523ms         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.15</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">87.</span>372ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37.</span>725us      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21.</span>854ms         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.15</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.</span>911ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.</span>620us    \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2316</span>  \n",
       "                                aten::cudnn_convolution         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.00</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.</span>745ms         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.45</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71.</span>201ms     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">221.</span>810us      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71.</span>497ms        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.83</span>%     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">105.</span>171ms     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">327.</span>636us    \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">321</span>  \n",
       "                                              aten::div         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.57</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43.</span>701ms         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.90</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">65.</span>879ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39.</span>331us       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.</span>326ms         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.49</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.</span>167ms       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.</span>070us    \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1675</span>  \n",
       "                                             aten::add_         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.54</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33.</span>856ms         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.90</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">65.</span>932ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.</span>205us      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32.</span>449ms         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.64</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34.</span>505ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.</span>714us    \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2516</span>  \n",
       "                                              aten::sum         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.28</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31.</span>303ms         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.86</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46.</span>424ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36.</span>962us      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17.</span>573ms         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.14</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17.</span>573ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.</span>991us    \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1256</span>  \n",
       "                                            aten::addmm         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.97</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28.</span>349ms         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.38</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41.</span>835ms     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">166.</span>012us       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.</span>517ms         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.36</span>%       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.</span>990ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19.</span>802us    \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">252</span>  \n",
       "                                              aten::add         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.82</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26.</span>940ms         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.29</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40.</span>992ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51.</span>627us      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.</span>840ms         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.79</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.</span>414ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.</span>154us    \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">794</span>  \n",
       "                                              aten::exp         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.09</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19.</span>971ms         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.51</span>%      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52.</span>658ms     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">180.</span>336us     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">682.</span>000us         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.16</span>%       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.</span>437ms      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22.</span>045us    \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">292</span>  \n",
       "-------------------------------------------------------  ------------  ------------  \n",
       "------------  ------------  ------------  ------------  ------------  ------------  \n",
       "------------  ------------  \n",
       "Self CPU time total: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">955.</span>230ms\n",
       "Self CUDA time total: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">424.</span>738ms\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "-------------------------------------------------------  ------------  ------------  \n",
       "------------  ------------  ------------  ------------  ------------  ------------  \n",
       "------------  ------------  \n",
       "                                                   Name    Self CPU %      Self CPU   CPU \n",
       "total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg \n",
       "# of Calls  \n",
       "-------------------------------------------------------  ------------  ------------  \n",
       "------------  ------------  ------------  ------------  ------------  ------------  \n",
       "------------  ------------  \n",
       "                                       cudaLaunchKernel        \u001b[1;36m26.61\u001b[0m%     \u001b[1;36m254.\u001b[0m222ms        \n",
       "\u001b[1;36m26.61\u001b[0m%     \u001b[1;36m254.\u001b[0m222ms      \u001b[1;36m16.\u001b[0m282us      \u001b[1;36m43.\u001b[0m567ms        \u001b[1;36m10.26\u001b[0m%      \u001b[1;36m43.\u001b[0m567ms       \u001b[1;36m2.\u001b[0m790us   \n",
       "\u001b[1;36m15614\u001b[0m  \n",
       "                             aten::convolution_backward         \u001b[1;36m5.90\u001b[0m%      \u001b[1;36m56.\u001b[0m383ms        \n",
       "\u001b[1;36m11.40\u001b[0m%     \u001b[1;36m108.\u001b[0m907ms     \u001b[1;36m310.\u001b[0m276us     \u001b[1;36m208.\u001b[0m844ms        \u001b[1;36m49.17\u001b[0m%     \u001b[1;36m218.\u001b[0m653ms     \u001b[1;36m622.\u001b[0m943us   \n",
       "\u001b[1;36m351\u001b[0m  \n",
       "                                              aten::mul         \u001b[1;36m5.81\u001b[0m%      \u001b[1;36m55.\u001b[0m523ms         \n",
       "\u001b[1;36m9.15\u001b[0m%      \u001b[1;36m87.\u001b[0m372ms      \u001b[1;36m37.\u001b[0m725us      \u001b[1;36m21.\u001b[0m854ms         \u001b[1;36m5.15\u001b[0m%      \u001b[1;36m26.\u001b[0m911ms      \u001b[1;36m11.\u001b[0m620us    \n",
       "\u001b[1;36m2316\u001b[0m  \n",
       "                                aten::cudnn_convolution         \u001b[1;36m5.00\u001b[0m%      \u001b[1;36m47.\u001b[0m745ms         \n",
       "\u001b[1;36m7.45\u001b[0m%      \u001b[1;36m71.\u001b[0m201ms     \u001b[1;36m221.\u001b[0m810us      \u001b[1;36m71.\u001b[0m497ms        \u001b[1;36m16.83\u001b[0m%     \u001b[1;36m105.\u001b[0m171ms     \u001b[1;36m327.\u001b[0m636us    \n",
       "\u001b[1;36m321\u001b[0m  \n",
       "                                              aten::div         \u001b[1;36m4.57\u001b[0m%      \u001b[1;36m43.\u001b[0m701ms         \n",
       "\u001b[1;36m6.90\u001b[0m%      \u001b[1;36m65.\u001b[0m879ms      \u001b[1;36m39.\u001b[0m331us       \u001b[1;36m6.\u001b[0m326ms         \u001b[1;36m1.49\u001b[0m%      \u001b[1;36m10.\u001b[0m167ms       \u001b[1;36m6.\u001b[0m070us    \n",
       "\u001b[1;36m1675\u001b[0m  \n",
       "                                             aten::add_         \u001b[1;36m3.54\u001b[0m%      \u001b[1;36m33.\u001b[0m856ms         \n",
       "\u001b[1;36m6.90\u001b[0m%      \u001b[1;36m65.\u001b[0m932ms      \u001b[1;36m26.\u001b[0m205us      \u001b[1;36m32.\u001b[0m449ms         \u001b[1;36m7.64\u001b[0m%      \u001b[1;36m34.\u001b[0m505ms      \u001b[1;36m13.\u001b[0m714us    \n",
       "\u001b[1;36m2516\u001b[0m  \n",
       "                                              aten::sum         \u001b[1;36m3.28\u001b[0m%      \u001b[1;36m31.\u001b[0m303ms         \n",
       "\u001b[1;36m4.86\u001b[0m%      \u001b[1;36m46.\u001b[0m424ms      \u001b[1;36m36.\u001b[0m962us      \u001b[1;36m17.\u001b[0m573ms         \u001b[1;36m4.14\u001b[0m%      \u001b[1;36m17.\u001b[0m573ms      \u001b[1;36m13.\u001b[0m991us    \n",
       "\u001b[1;36m1256\u001b[0m  \n",
       "                                            aten::addmm         \u001b[1;36m2.97\u001b[0m%      \u001b[1;36m28.\u001b[0m349ms         \n",
       "\u001b[1;36m4.38\u001b[0m%      \u001b[1;36m41.\u001b[0m835ms     \u001b[1;36m166.\u001b[0m012us       \u001b[1;36m1.\u001b[0m517ms         \u001b[1;36m0.36\u001b[0m%       \u001b[1;36m4.\u001b[0m990ms      \u001b[1;36m19.\u001b[0m802us    \n",
       "\u001b[1;36m252\u001b[0m  \n",
       "                                              aten::add         \u001b[1;36m2.82\u001b[0m%      \u001b[1;36m26.\u001b[0m940ms         \n",
       "\u001b[1;36m4.29\u001b[0m%      \u001b[1;36m40.\u001b[0m992ms      \u001b[1;36m51.\u001b[0m627us      \u001b[1;36m11.\u001b[0m840ms         \u001b[1;36m2.79\u001b[0m%      \u001b[1;36m14.\u001b[0m414ms      \u001b[1;36m18.\u001b[0m154us    \n",
       "\u001b[1;36m794\u001b[0m  \n",
       "                                              aten::exp         \u001b[1;36m2.09\u001b[0m%      \u001b[1;36m19.\u001b[0m971ms         \n",
       "\u001b[1;36m5.51\u001b[0m%      \u001b[1;36m52.\u001b[0m658ms     \u001b[1;36m180.\u001b[0m336us     \u001b[1;36m682.\u001b[0m000us         \u001b[1;36m0.16\u001b[0m%       \u001b[1;36m6.\u001b[0m437ms      \u001b[1;36m22.\u001b[0m045us    \n",
       "\u001b[1;36m292\u001b[0m  \n",
       "-------------------------------------------------------  ------------  ------------  \n",
       "------------  ------------  ------------  ------------  ------------  ------------  \n",
       "------------  ------------  \n",
       "Self CPU time total: \u001b[1;36m955.\u001b[0m230ms\n",
       "Self CUDA time total: \u001b[1;36m424.\u001b[0m738ms\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb84b59",
   "metadata": {},
   "source": [
    "### Save to txt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f9728d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cuda_time_total\", row_limit=100)\n",
    "with open(\"profile_cuda.txt\", \"w\") as f:\n",
    "    f.write(output)\n",
    "    \n",
    "output = prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cpu_time_total\", row_limit=100)\n",
    "with open(\"profile_cpu.txt\", \"w\") as f:\n",
    "    f.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c0a3b",
   "metadata": {},
   "source": [
    "**Conclusion**: jit was slowing things down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec9ab6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ae13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd9b487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch # 1, avg loss: 57.204149: 100%|██████████| 1/1 [02:20<00:00, 140.16s/it]\n"
     ]
    }
   ],
   "source": [
    "activities = [\n",
    "    torch.profiler.ProfilerActivity.CPU,\n",
    "    torch.profiler.ProfilerActivity.CUDA,\n",
    "]\n",
    "kws = dict(\n",
    "    activities=activities,\n",
    "    record_shapes=True,\n",
    "    with_stack=True,\n",
    ")\n",
    "with torch.profiler.profile(**kws) as prof:\n",
    "    self.train(1, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee4b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cuda_time_total\", row_limit=100)\n",
    "with open(\"profile_cuda.txt\", \"w\") as f:\n",
    "    f.write(output)\n",
    "    \n",
    "output = prof.key_averages(group_by_stack_n=5).table(sort_by=\"self_cpu_time_total\", row_limit=100)\n",
    "with open(\"profile_cpu.txt\", \"w\") as f:\n",
    "    f.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e423edbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e1611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d4c5cd9",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61186a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE(ConfigVAE(\n",
    "    n_latent_scales=2, n_groups_per_scale=20, n_latent_per_group=7,\n",
    "    scale_init=False, residual_kl=True, ada_groups=True, # separable=False,\n",
    "))\n",
    "tr = TrainerVAE(\n",
    "    model=torch.compile(vae),\n",
    "    cfg=ConfigTrainVAE(\n",
    "        lr=0.002, batch_size=500, epochs=2000, grad_clip=1000,\n",
    "        lambda_anneal=True, lambda_init=1e-7, lambda_norm=1e-2,\n",
    "        kl_beta=0.25, kl_anneal_cycles=1, \n",
    "        scheduler_kws={'T_max': 660.0, 'eta_min': 1e-05},   \n",
    "        optimizer='adamax_fast',\n",
    "    ),\n",
    "    device='cuda:1',\n",
    ")\n",
    "vae.cfg.total_latents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cdea108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e51b5f6a2624475997333e7fe69fd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "BackendCompilerFailed",
     "evalue": "debug_wrapper raised RuntimeError: Function ConvolutionBackward0 returned an invalid gradient at index 1 - expected device cuda:1 but got cuda:0\n\nSet torch._dynamo.config.verbose=True for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    torch._dynamo.config.suppress_errors = True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/output_graph.py:670\u001b[0m, in \u001b[0;36mOutputGraph.call_user_compiler\u001b[0;34m(self, gm)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_example_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m _step_logger()(logging\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone compiler function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/debug_utils.py:1055\u001b[0m, in \u001b[0;36mwrap_backend_debug.<locals>.debug_wrapper\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1055\u001b[0m     compiled_gm \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_gm\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/__init__.py:1390\u001b[0m, in \u001b[0;36m_TorchCompileInductorWrapper.__call__\u001b[0;34m(self, model_, inputs_)\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompile_fx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compile_fx\n\u001b[0;32m-> 1390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompile_fx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_patches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_inductor/compile_fx.py:455\u001b[0m, in \u001b[0;36mcompile_fx\u001b[0;34m(model_, example_inputs_, inner_compile, config_patches)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m overrides\u001b[38;5;241m.\u001b[39mpatch_functions():\n\u001b[1;32m    451\u001b[0m \n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# TODO: can add logging before/after the call to create_aot_dispatcher_function\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# in torch._functorch/aot_autograd.py::aot_module_simplified::aot_function_simplified::new_func\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;66;03m# once torchdynamo is merged into pytorch\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maot_autograd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselect_decomp_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_cut_rematerialization_partition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minductor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_inference_input_mutations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/backends/common.py:48\u001b[0m, in \u001b[0;36maot_autograd.<locals>.compiler_fn\u001b[0;34m(gm, example_inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m enable_aot_logging():\n\u001b[0;32m---> 48\u001b[0m     cg \u001b[38;5;241m=\u001b[39m \u001b[43maot_module_simplified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot_autograd\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:2805\u001b[0m, in \u001b[0;36maot_module_simplified\u001b[0;34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, hasher_type, static_argnums, keep_inference_input_mutations)\u001b[0m\n\u001b[1;32m   2803\u001b[0m full_args\u001b[38;5;241m.\u001b[39mextend(args)\n\u001b[0;32m-> 2805\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunctional_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2808\u001b[0m \u001b[43m    \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2809\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2811\u001b[0m \u001b[38;5;66;03m# TODO: There is something deeply wrong here; compiled_fn running with\u001b[39;00m\n\u001b[1;32m   2812\u001b[0m \u001b[38;5;66;03m# the boxed calling convention, but aot_module_simplified somehow\u001b[39;00m\n\u001b[1;32m   2813\u001b[0m \u001b[38;5;66;03m# historically returned a function that was not the boxed calling\u001b[39;00m\n\u001b[1;32m   2814\u001b[0m \u001b[38;5;66;03m# convention.  This should get fixed...\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/utils.py:163\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 163\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:2498\u001b[0m, in \u001b[0;36mcreate_aot_dispatcher_function\u001b[0;34m(flat_fn, flat_args, aot_config)\u001b[0m\n\u001b[1;32m   2496\u001b[0m \u001b[38;5;66;03m# You can put more passes here\u001b[39;00m\n\u001b[0;32m-> 2498\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(compiled_fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_boxed_call\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:1713\u001b[0m, in \u001b[0;36maot_wrapper_dedupe\u001b[0;34m(flat_fn, flat_args, aot_config, compiler_fn)\u001b[0m\n\u001b[1;32m   1712\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ok:\n\u001b[0;32m-> 1713\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleaf_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;66;03m# Strategy 2: Duplicate specialize.\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   1717\u001b[0m \u001b[38;5;66;03m# In Haskell types, suppose you have:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;66;03m#   }\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;66;03m#   keep_arg_mask = [True, True, False, True]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:2087\u001b[0m, in \u001b[0;36maot_dispatch_autograd\u001b[0;34m(flat_fn, flat_args, aot_config)\u001b[0m\n\u001b[1;32m   2086\u001b[0m     flattened_joints, _ \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_flatten(joint_inputs)\n\u001b[0;32m-> 2087\u001b[0m     fx_g \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoint_forward_backward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompositions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2088\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mjoint_inputs\u001b[49m\n\u001b[1;32m   2089\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2091\u001b[0m \u001b[38;5;66;03m# There should be *NO* mutating ops in the graph at this point.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/fx/experimental/proxy_tensor.py:714\u001b[0m, in \u001b[0;36mmake_fx.<locals>.wrapped\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m decompose(decomposition_table), fake_tensor_mode, python_dispatcher_mode, \\\n\u001b[1;32m    713\u001b[0m      sym_mode, proxy_mode, disable_autocast_cache(), disable_proxy_modes_tracing(enable_current\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 714\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrap_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfx_tracer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfx_tracer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcrete_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mphs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# TODO: kind of a bad way to do it, should maybe figure out a better way\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:209\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/fx/experimental/proxy_tensor.py:443\u001b[0m, in \u001b[0;36mdispatch_trace\u001b[0;34m(root, tracer, concrete_args)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdispatch_trace\u001b[39m(\n\u001b[1;32m    439\u001b[0m         root: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, Callable],\n\u001b[1;32m    440\u001b[0m         tracer: Tracer,\n\u001b[1;32m    441\u001b[0m         concrete_args: Optional[Tuple[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GraphModule:\n\u001b[0;32m--> 443\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcrete_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     name \u001b[38;5;241m=\u001b[39m root\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(root, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule) \u001b[38;5;28;01melse\u001b[39;00m root\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:209\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/fx/_symbolic_trace.py:778\u001b[0m, in \u001b[0;36mTracer.trace\u001b[0;34m(self, root, concrete_args)\u001b[0m\n\u001b[1;32m    772\u001b[0m         _autowrap_check(\n\u001b[1;32m    773\u001b[0m             patcher, module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_function_ids\n\u001b[1;32m    774\u001b[0m         )\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_node(\n\u001b[1;32m    776\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    777\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 778\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_arg(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m),),\n\u001b[1;32m    779\u001b[0m         {},\n\u001b[1;32m    780\u001b[0m         type_expr\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__annotations__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    781\u001b[0m     )\n\u001b[1;32m    783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmodule_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/fx/_symbolic_trace.py:652\u001b[0m, in \u001b[0;36mTracer.create_args_for_root.<locals>.flatten_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    651\u001b[0m tree_args \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(\u001b[38;5;28mlist\u001b[39m(args), in_spec)\n\u001b[0;32m--> 652\u001b[0m tree_out \u001b[38;5;241m=\u001b[39m \u001b[43mroot_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtree_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m out_args, out_spec \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_flatten(tree_out)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/fx/experimental/proxy_tensor.py:459\u001b[0m, in \u001b[0;36mwrap_key.<locals>.wrapped\u001b[0;34m(*proxies)\u001b[0m\n\u001b[1;32m    457\u001b[0m     track_tensor_tree(flat_tensors, flat_proxies, constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tracer\u001b[38;5;241m=\u001b[39mtracer)\n\u001b[0;32m--> 459\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m out \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_map_only(\n\u001b[1;32m    461\u001b[0m     torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m t: get_proxy_slot(t, tracer, t, \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mproxy),\n\u001b[1;32m    463\u001b[0m     out\n\u001b[1;32m    464\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:1156\u001b[0m, in \u001b[0;36mcreate_forward_or_joint_functionalized.<locals>.traced_joint\u001b[0;34m(primals, tangents)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraced_joint\u001b[39m(primals, tangents):\n\u001b[0;32m-> 1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctionalized_f_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtangents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:1108\u001b[0m, in \u001b[0;36mcreate_forward_or_joint_functionalized.<locals>.functionalized_f_helper\u001b[0;34m(primals, maybe_tangents)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;66;03m# Run the joint\u001b[39;00m\n\u001b[0;32m-> 1108\u001b[0m     f_outs \u001b[38;5;241m=\u001b[39m \u001b[43mflat_fn_no_input_mutations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_primals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_tangents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_input_mutations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:1076\u001b[0m, in \u001b[0;36mflat_fn_no_input_mutations\u001b[0;34m(fn, primals, maybe_tangents, meta, keep_input_mutations)\u001b[0m\n\u001b[1;32m   1075\u001b[0m     primals_after_cloning \u001b[38;5;241m=\u001b[39m primals\n\u001b[0;32m-> 1076\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mflat_fn_with_synthetic_bases_expanded\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals_after_cloning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaybe_tangents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_input_mutations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:1048\u001b[0m, in \u001b[0;36mflat_fn_with_synthetic_bases_expanded\u001b[0;34m(fn, primals_before_cloning, primals_after_cloning, maybe_tangents, meta, keep_input_mutations)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(meta\u001b[38;5;241m.\u001b[39mfw_metadata\u001b[38;5;241m.\u001b[39minput_info) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(primals)\n\u001b[0;32m-> 1048\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mforward_or_joint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals_before_cloning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaybe_tangents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_input_mutations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:1017\u001b[0m, in \u001b[0;36mforward_or_joint\u001b[0;34m(fn, primals_before_cloning, primals_after_cloning, maybe_tangents, meta, keep_input_mutations)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m fx_traceback\u001b[38;5;241m.\u001b[39mpreserve_node_meta():\n\u001b[0;32m-> 1017\u001b[0m         backward_out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m            \u001b[49m\u001b[43mneeded_outs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgrad_primals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneeded_tangents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1023\u001b[0m backward_out_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(backward_out)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:269\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(overridable_args):\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverridable_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_grads_batched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m only_inputs:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/overrides.py:1534\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1534\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_inductor/overrides.py:38\u001b[0m, in \u001b[0;36mAutogradMonkeypatch.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m replacements[func](\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function ConvolutionBackward0 returned an invalid gradient at index 1 - expected device cuda:1 but got cuda:0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBackendCompilerFailed\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:82\u001b[0m, in \u001b[0;36mOptimizedModule.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamo_ctx\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_orig_mod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:209\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m dynamic_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/Dropbox/git/_MTMST/model/vae2d.py:77\u001b[0m, in \u001b[0;36mVAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     75\u001b[0m \t\tlatents\u001b[38;5;241m.\u001b[39mappend(z)\n\u001b[1;32m     76\u001b[0m \t\u001b[38;5;66;03m# 'combiner_dec'\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \ts \u001b[38;5;241m=\u001b[39m cell(s, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     78\u001b[0m \tidx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:337\u001b[0m, in \u001b[0;36mcatch_errors_wrapper.<locals>.catch_errors\u001b[0;34m(frame, cache_size)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(frame, cache_size, hooks)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock:\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:404\u001b[0m, in \u001b[0;36mconvert_frame.<locals>._convert_frame\u001b[0;34m(frame, cache_size, hooks)\u001b[0m\n\u001b[1;32m    402\u001b[0m counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43minner_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:104\u001b[0m, in \u001b[0;36mwrap_convert_context.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mgraph_module\u001b[38;5;241m.\u001b[39m_forward_from_src \u001b[38;5;241m=\u001b[39m fx_forward_from_src_skip_result\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_set_grad_enabled(prior_grad_mode)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:262\u001b[0m, in \u001b[0;36mconvert_frame_assert.<locals>._convert_frame_assert\u001b[0;34m(frame, cache_size, hooks)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m initial_grad_state\n\u001b[1;32m    260\u001b[0m initial_grad_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_grad_enabled()\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/utils.py:163\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     compilation_metrics[key] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    162\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 163\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# print(f\"Dynamo timer: key={key}, latency={latency:.2f} sec\")\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:324\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(code, globals, locals, builtins, compiler_fn, one_graph, export, hooks, frame)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mcount():\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 324\u001b[0m         out_code \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m         orig_code_map[out_code] \u001b[38;5;241m=\u001b[39m code\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/bytecode_transformation.py:445\u001b[0m, in \u001b[0;36mtransform_code_object\u001b[0;34m(code, transformations, safe)\u001b[0m\n\u001b[1;32m    442\u001b[0m instructions \u001b[38;5;241m=\u001b[39m cleaned_instructions(code, safe)\n\u001b[1;32m    443\u001b[0m propagate_line_nums(instructions)\n\u001b[0;32m--> 445\u001b[0m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:311\u001b[0m, in \u001b[0;36m_compile.<locals>.transform\u001b[0;34m(instructions, code_options)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m output\n\u001b[1;32m    299\u001b[0m tracer \u001b[38;5;241m=\u001b[39m InstructionTranslator(\n\u001b[1;32m    300\u001b[0m     instructions,\n\u001b[1;32m    301\u001b[0m     code,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     mutated_closure_cell_contents,\n\u001b[1;32m    310\u001b[0m )\n\u001b[0;32m--> 311\u001b[0m \u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m output \u001b[38;5;241m=\u001b[39m tracer\u001b[38;5;241m.\u001b[39moutput\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py:1726\u001b[0m, in \u001b[0;36mInstructionTranslator.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1725\u001b[0m     _step_logger()(logging\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchdynamo start tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1726\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py:576\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mpush_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m (\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstruction_pointer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mshould_exit\n\u001b[0;32m--> 576\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m     ):\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py:540\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst\u001b[38;5;241m.\u001b[39mopname):\n\u001b[1;32m    539\u001b[0m         unimplemented(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minst\u001b[38;5;241m.\u001b[39mopname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inst\u001b[38;5;241m.\u001b[39mopname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN_VALUE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py:1792\u001b[0m, in \u001b[0;36mInstructionTranslator.RETURN_VALUE\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m   1787\u001b[0m _step_logger()(\n\u001b[1;32m   1788\u001b[0m     logging\u001b[38;5;241m.\u001b[39mINFO,\n\u001b[1;32m   1789\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchdynamo done tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (RETURN_VALUE)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1790\u001b[0m )\n\u001b[1;32m   1791\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN_VALUE triggered compile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1792\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_subgraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreason\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGraphCompileReason\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39madd_output_instructions([create_instruction(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN_VALUE\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/output_graph.py:541\u001b[0m, in \u001b[0;36mOutputGraph.compile_subgraph\u001b[0;34m(self, tx, partial_convert, reason)\u001b[0m\n\u001b[1;32m    538\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count_calls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pass2\u001b[38;5;241m.\u001b[39mgraph_outputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    540\u001b[0m     output\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 541\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_and_call_fx_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_output_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m     )\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pass2\u001b[38;5;241m.\u001b[39mgraph_outputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    545\u001b[0m         output\u001b[38;5;241m.\u001b[39mappend(pass2\u001b[38;5;241m.\u001b[39mcreate_store(graph_output_var))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/output_graph.py:588\u001b[0m, in \u001b[0;36mOutputGraph.compile_and_call_fx_graph\u001b[0;34m(self, tx, rv, root)\u001b[0m\n\u001b[1;32m    586\u001b[0m assert_no_fake_params_or_buffers(gm)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tracing(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracing_context):\n\u001b[0;32m--> 588\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m disable(compiled_fn)\n\u001b[1;32m    591\u001b[0m counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstats\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique_graphs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/utils.py:163\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     compilation_metrics[key] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    162\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 163\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# print(f\"Dynamo timer: key={key}, latency={latency:.2f} sec\")\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/output_graph.py:675\u001b[0m, in \u001b[0;36mOutputGraph.call_user_compiler\u001b[0;34m(self, gm)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    674\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m gm\u001b[38;5;241m.\u001b[39mforward\n\u001b[0;32m--> 675\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BackendCompilerFailed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiler_fn, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn\n",
      "\u001b[0;31mBackendCompilerFailed\u001b[0m: debug_wrapper raised RuntimeError: Function ConvolutionBackward0 returned an invalid gradient at index 1 - expected device cuda:1 but got cuda:0\n\nSet torch._dynamo.config.verbose=True for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    torch._dynamo.config.suppress_errors = True\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tr.model.train()\n",
    "\n",
    "for _ in range(5):\n",
    "    for x, norm in tqdm(iter(tr.dl_trn)):\n",
    "        tr.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d98c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669cc8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.train(comment='compiled_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93e0bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5590fe96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f852a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
