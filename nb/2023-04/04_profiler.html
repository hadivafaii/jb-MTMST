

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>(04) PyTorch profiler &#8212; MT/MST project</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'nb/2023-04/04_profiler';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="(06) Sim – kNN analysis" href="06_sim-kNN.html" />
    <link rel="prev" title="(04) Dan notebook" href="04_dan.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../md/intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.jpg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/logo.jpg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../md/intro.html">
                    Welcome
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">January 2022</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../md/2022-01.html">Summary</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../md/2022-01_updates.html">Updates</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../2022-01/jan-23-2022.html">Jan 23rd, 2022 (jb tutorial)</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">October 2022</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../md/2022-10.html">Summary</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../md/2022-10_updates.html">Updates</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../2022-10/oct-01-2022.html">Oct 1st, 2022 (Load Wild Data)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2022-10/oct-06-2022.html">Oct 6th, 2022 (Python processed)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2022-10/oct-07-2022.html">Oct 7th, 2022 (Linear: STA – draft)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2022-10/oct-08-2022.html">Oct 8th, 2022 (Linear: STA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2022-10/oct-09-2022.html">Oct 9th, 2022 (Opticflow stats)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2022-10/oct-11-2022.html">Oct 11th, 2022 (Rot Conv verify)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2022-10/oct-16-2022.html">Oct 16th, 2022 (Linear: GLM – spatial)</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">January 2023</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../md/2023-01.html">Summary</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../md/2023-01_updates.html">Updates</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../2023-01/08_wild.html">(08) Wild play</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-01/10_nardin.html">(10) Nardin play</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-01/15_sim-draft.html">(15) Simulation – draft</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-01/16_sim-wrong.html">(16) Simulation – wrong</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-01/21_sim-explore.html">(21) Simulation – explore</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-01/23_sim-self-draft.html">(23) Simulation – self-motion aspect [draft]</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-01/24_sim-self-draft.html">(24) Simulation – self [still draft]</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-01/28_sim-self.html">(28) Simulation – self [velocity: new way]</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-01/29_sim-full-draft.html">(29) Simulation – full [draft]</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-01/30_sim-full-final.html">(30) Simulation – full [final]</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">February 2023</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../md/2023-02.html">Summary</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../md/2023-02_updates.html">Updates</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../2023-02/01_play-nvae.html">(01) NVAE – play</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-02/02_play-vae2d.html">(02) VAE2D – play</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-02/09_rot-conv.html">(09) RotConv2d – verified</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-02/23_sim-gen.html">(23) Simulation – generate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-02/24_sim-gen-decoupled.html">(24) Simulation – generate (fix &amp; obj uncoupled)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-02/24_sim-gen-save.html">(24) Simulation – generate (save)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-02/25_fit-cuda.html">(25) Fit – cuda (gaban)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-02/25_fit-cuda0.html">(25) Fit – cuda0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-02/25_fit-cuda1.html">(25) Fit – cuda1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-02/25_fit-cuda2.html">(25) Fit – cuda2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-02/30_kl-balancer-debug.html">(30) KL Balancer</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">March 2023</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../md/2023-03.html">Summary</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../md/2023-03_updates.html">Updates</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../2023-03/17_sim-new-draft.html">(17) Sim New – draft</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-03/22_sim-new-draft.html">(22) Sim New – draft</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-03/23_sim-new.html">(23) Sim New – visualize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-03/30_fit-cuda.html">(30) Fit – cuda</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-03/30_fit-cuda0.html">(30) Fit – cuda0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-03/30_fit-cuda1.html">(30) Fit – cuda1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-03/30_fit-cuda2.html">(30) Fit – cuda2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-03/30_sim-final.html">(30) Sim – added <code class="docutils literal notranslate"><span class="pre">terrain</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-03/31_sim-factors.html">(31) Sim – true generative factors</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">April 2023</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../md/2023-04.html">Summary</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../../md/2023-04_updates.html">Updates</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="02_fit-lin.html">(02) Fit neurons – Linear</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_fit-glm.html">(03) Fit neurons – GLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_loop-glm.html">(03) Fit neurons – GLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_loop-ridge.html">(03) Fit neurons – Ridge</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_dan.html">(04) Dan notebook</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">(04) PyTorch profiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="06_sim-kNN.html">(06) Sim – kNN analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="07_readout-3d.html">(07) Readout: 3D conv</a></li>
<li class="toctree-l2"><a class="reference internal" href="07_readout-sep.html">(07) Readout: Separable</a></li>
<li class="toctree-l2"><a class="reference internal" href="08_GLM-clu090.html">(08) Reservoir + GLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="08_GLM-clu096.html">(08) Reservoir + GLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="08_sim-accept-filter.html">(08) Sim – behavior of <code class="docutils literal notranslate"><span class="pre">filter()</span></code> when <code class="docutils literal notranslate"><span class="pre">dim=65</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="08_sim-dim65-manyseeds.html">(08) Sim – many seeds <code class="docutils literal notranslate"><span class="pre">dim=65</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="09_sim-final-save.html">(09) Sim – generate &amp; save <code class="docutils literal notranslate"><span class="pre">dim=65</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="10_GLM-clu090.html">(10) Reservoir + GLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="12_GLM-pix.html">(12) Reservoir + GLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="13_dim17-accept-filter.html">(13) Sim – behavior of <code class="docutils literal notranslate"><span class="pre">filter()</span></code> when <code class="docutils literal notranslate"><span class="pre">dim=17</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="13_dim17-dists.html">(13) Sim – dists for <code class="docutils literal notranslate"><span class="pre">dim=17</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="13_fit-cuda.html">(13) Fit – cuda</a></li>
<li class="toctree-l2"><a class="reference internal" href="13_fit-cuda0.html">(13) Fit – cuda0</a></li>
<li class="toctree-l2"><a class="reference internal" href="13_fit-cuda1.html">(13) Fit – cuda1</a></li>
<li class="toctree-l2"><a class="reference internal" href="13_fit-cuda2.html">(13) Fit – cuda2</a></li>
<li class="toctree-l2"><a class="reference internal" href="14_GLM-loop.html">(14) Reservoir + GLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="15_GLM-loop.html">(15) Reservoir + GLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="16_GLM-save.html">(16) Reservoir + GLM + Save</a></li>
<li class="toctree-l2"><a class="reference internal" href="18_fixate1-glm-GABAN.html">(18) Fixate1 + GLM (GABAN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="18_fixate1-glm-KABA.html">(18) Fixate1 + GLM (KABA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="20_eval.html">(20) Eval</a></li>
<li class="toctree-l2"><a class="reference internal" href="23_nardin.html">(23) Nardin notebook</a></li>
<li class="toctree-l2"><a class="reference internal" href="24_meeting-plots.html">(24) Make some figs</a></li>
<li class="toctree-l2"><a class="reference internal" href="25_diameters.html">(25) Diameters: dist</a></li>
<li class="toctree-l2"><a class="reference internal" href="26_neural-fits-GABAN.html">(26) Neural results plot (GABAN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="26_neural-fits-KABA.html">(26) Neural results plot (KABA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="29_combine-fits.html">(29) Combine neural fits</a></li>
<li class="toctree-l2"><a class="reference internal" href="%3F%3F_logging.html">(??) Regression – DCI</a></li>
<li class="toctree-l2"><a class="reference internal" href="tmp.html">(??) Tmp</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">May 2023</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../md/2023-05.html">Summary</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../md/2023-05_updates.html">Updates</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/01_beta-fits-GABAN.html">(01) Neural <span class="math notranslate nohighlight">\(\beta\)</span> results (GABAN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/01_beta-fits-KABA.html">(01) Neural <span class="math notranslate nohighlight">\(\beta\)</span> results (KABA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/02_combine-beta-fits.html">(02) Combine <span class="math notranslate nohighlight">\(\beta\)</span> fits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/03_combine-fits-subset.html">(03) Combine neural fits (subset)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/03_dci-beta.html">(03) DCI vs. <span class="math notranslate nohighlight">\(\beta\)</span> (KABA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/04_debug-obj.html">(04) Debug – obj</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/04_rev-corr.html">(04) Visualize Receptive Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/05_neural-align.html">(05) Neural <span class="math notranslate nohighlight">\(\beta\)</span> alignment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/05_tr-analysis-GABAN.html">(05) Trainers (KABA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/05_tr-analysis-KABA.html">(05) Trainers (KABA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/07_neural-analysis-tmp-GABAN.html">(07) Neural analysis (GABAN; tmp)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/07_neural-analysis-tmp-KABA.html">(07) Neural analysis (KABA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/09_neural-analysis-GABAN.html">(09) Neural analysis (GABAN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/09_neural-analysis-KABA.html">(09) Neural analysis (KABA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/10_combine-fits-updated.html">(10) Combine neural fits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/12_resume-fit-GABAN.html">(12) Resume fit (GABAN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/15_PCA-NMF-Raw.html">(15) PCA, NMF, Raw</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/Fig_align.html">Fig: Alignment scores</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/Fig_DCI.html">Fig: DCI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/Fig_EPE-NELBO.html">Fig: EPE/NELBO</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/Fig_intro.html">Fig: Intro, etc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/Fig_MI.html">Fig: MI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/Fig_psth.html">Fig: PSTH + STA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/Fig_z-traversal.html">Load</a></li>






<li class="toctree-l2"><a class="reference internal" href="../2023-05/Table_Neural.html">Table: Neural</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/Table_pvals.html">Table: pvals (perf + align)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2023-05/tmp.html">tmp</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/hadivafaii/jb-MTMST" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/hadivafaii/jb-MTMST/issues/new?title=Issue%20on%20page%20%2Fnb/2023-04/04_profiler.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/nb/2023-04/04_profiler.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>(04) PyTorch profiler</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trainer">Trainer</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#save-to-txt">Save to txt?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compile">Compile</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="pytorch-profiler">
<h1>(04) PyTorch profiler<a class="headerlink" href="#pytorch-profiler" title="Permalink to this headline">#</a></h1>
<p><strong>Motivation</strong>: &#64;torch.jit.script was slowing things down <br></p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>


<span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>

<span class="c1"># tmp &amp; extras dir</span>
<span class="n">git_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;HOME&#39;</span><span class="p">],</span> <span class="s1">&#39;Dropbox/git&#39;</span><span class="p">)</span>
<span class="n">extras_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">git_dir</span><span class="p">,</span> <span class="s1">&#39;jb-MTMST/_extras&#39;</span><span class="p">)</span>
<span class="n">fig_base_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">git_dir</span><span class="p">,</span> <span class="s1">&#39;jb-MTMST/figs&#39;</span><span class="p">)</span>
<span class="n">tmp_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">git_dir</span><span class="p">,</span> <span class="s1">&#39;jb-MTMST/tmp&#39;</span><span class="p">)</span>

<span class="c1"># GitHub</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">git_dir</span><span class="p">,</span> <span class="s1">&#39;_MTMST&#39;</span><span class="p">))</span>
<span class="kn">from</span> <span class="nn">model.train_vae</span> <span class="kn">import</span> <span class="n">TrainerVAE</span><span class="p">,</span> <span class="n">ConfigTrainVAE</span>
<span class="kn">from</span> <span class="nn">model.vae2d</span> <span class="kn">import</span> <span class="n">VAE</span><span class="p">,</span> <span class="n">ConfigVAE</span>
<span class="kn">from</span> <span class="nn">analysis.opticflow</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">figures.fighelper</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># warnings, tqdm, &amp; style</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">DeprecationWarning</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">rich.jupyter</span> <span class="kn">import</span> <span class="nb">print</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">set_style</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
<section id="trainer">
<h2>Trainer<a class="headerlink" href="#trainer" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vae</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">(</span><span class="n">ConfigVAE</span><span class="p">(</span>
    <span class="n">n_latent_scales</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_groups_per_scale</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_latent_per_group</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
    <span class="n">scale_init</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">residual_kl</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ada_groups</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># separable=False,</span>
<span class="p">))</span>
<span class="bp">self</span> <span class="o">=</span> <span class="n">TrainerVAE</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">vae</span><span class="p">,</span>
    <span class="n">cfg</span><span class="o">=</span><span class="n">ConfigTrainVAE</span><span class="p">(</span>
        <span class="n">lr</span><span class="o">=</span><span class="mf">0.002</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">grad_clip</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">lambda_anneal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">lambda_init</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span> <span class="n">lambda_norm</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span>
        <span class="n">kl_beta</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">kl_anneal_cycles</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
        <span class="n">scheduler_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;T_max&#39;</span><span class="p">:</span> <span class="mf">660.0</span><span class="p">,</span> <span class="s1">&#39;eta_min&#39;</span><span class="p">:</span> <span class="mf">1e-05</span><span class="p">},</span>   
        <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adamax_fast&#39;</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">vae</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">total_latents</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>210
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vae</span><span class="o">.</span><span class="n">print</span><span class="p">()</span>
<span class="n">vae</span><span class="o">.</span><span class="n">scales</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">+--------------+------------+
| Module Name  | Num Params |
+--------------+------------+
|     VAE      |  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">17.0</span> Mil  |
|     ---      |    ---     |
|     stem     |   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">1.1</span> K    |
| pre_process  |   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">96.0</span> K   |
|  enc_tower   |  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">9.4</span> Mil   |
|     enc0     |   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">16.6</span> K   |
| enc_sampler  |  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">1.4</span> Mil   |
| dec_sampler  |  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">1.4</span> Mil   |
|    expand    |   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">71.0</span> K   |
|  dec_tower   |  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">4.5</span> Mil   |
| post_process |   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">40.0</span> K   |
|     out      |    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">578</span>     |
+--------------+------------+ 


</pre>
</div><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[8, 4]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">vae</span><span class="o">.</span><span class="n">all_conv_layers</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">vae</span><span class="o">.</span><span class="n">all_log_norm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(291, 287)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># neither epe, nor _normalize have jit. furthermore, _normalize uses linalg.vector_norm</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch # 100, avg loss: 4.861284: 100%|██████████| 100/100 [1:49:38&lt;00:00, 65.79s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 1h 47min 2s, sys: 3min 38s, total: 1h 50min 41s
Wall time: 1h 49min 39s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dl_trn</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 80/80 [00:18&lt;00:00,  4.25it/s]
100%|██████████| 80/80 [00:16&lt;00:00,  4.93it/s]
100%|██████████| 80/80 [00:17&lt;00:00,  4.71it/s]
100%|██████████| 80/80 [00:14&lt;00:00,  5.49it/s]
100%|██████████| 80/80 [00:14&lt;00:00,  5.67it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 1min 21s, sys: 1.53 s, total: 1min 22s
Wall time: 1min 20s
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># was with bunch of jit at Normal</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 80/80 [00:21&lt;00:00,  3.81it/s]
100%|██████████| 80/80 [00:15&lt;00:00,  5.09it/s]
100%|██████████| 80/80 [00:17&lt;00:00,  4.57it/s]
100%|██████████| 80/80 [00:14&lt;00:00,  5.35it/s]
100%|██████████| 80/80 [00:15&lt;00:00,  5.00it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 1min 26s, sys: 1.65 s, total: 1min 27s
Wall time: 1min 25s
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># was with torch.linalg.vector_norm</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 80/80 [00:14&lt;00:00,  5.57it/s]
100%|██████████| 80/80 [00:13&lt;00:00,  6.07it/s]
100%|██████████| 80/80 [00:11&lt;00:00,  6.92it/s]
100%|██████████| 80/80 [00:12&lt;00:00,  6.27it/s]
100%|██████████| 80/80 [00:11&lt;00:00,  6.88it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 1min 4s, sys: 1.64 s, total: 1min 6s
Wall time: 1min 3s
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">model.utils_model</span> <span class="kn">import</span> <span class="n">kl_balancer</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
  0%|          | 0/10 [00:00&lt;?, ?it/s]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span> 
    <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_iters_warmup</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>gstep # 61, nelbo: 15.907, grad: 228.0:   0%|          | 0/10 [05:06&lt;?, ?it/s]      
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
File &lt;timed exec&gt;:2, in &lt;module&gt;

File ~/Dropbox/git/_MTMST/model/train_vae.py:84, in TrainerVAE.iteration(self, epoch, **kwargs)
     82 # forward + loss
     83 with torch.cuda.amp.autocast(enabled=self.cfg.use_amp):
---&gt; 84 	y, _, q, p = self.model(x)
     85 	epe = self.model.loss_recon(x=x, y=y, w=1/norm)
     86 	kl_all, kl_diag = self.model.loss_kl(q, p)

File ~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)
   1496 # If we don&#39;t have any hooks, we want to skip the rest of the logic in
   1497 # this function, and just call forward.
   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
   1499         or _global_backward_pre_hooks or _global_backward_hooks
   1500         or _global_forward_hooks or _global_forward_pre_hooks):
-&gt; 1501     return forward_call(*args, **kwargs)
   1502 # Do not call functions when jit is used
   1503 full_backward_hooks, non_full_backward_hooks = [], []

KeyboardInterrupt: 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span> 
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dl_trn</span><span class="p">))):</span>
        <span class="n">gstep</span> <span class="o">=</span> <span class="n">e</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dl_trn</span><span class="p">)</span> <span class="o">+</span> <span class="n">i</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">epe</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">loss_recon</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">norm</span><span class="p">)</span>
        <span class="n">kl_all</span><span class="p">,</span> <span class="n">kl_diag</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">loss_kl</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
        <span class="c1"># balance kl</span>
        <span class="n">balanced_kl</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">kl_vals</span> <span class="o">=</span> <span class="n">kl_balancer</span><span class="p">(</span>
            <span class="n">kl_all</span><span class="o">=</span><span class="n">kl_all</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="p">,</span>
            <span class="n">coeff</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">[</span><span class="n">gstep</span><span class="p">],</span>
            <span class="n">beta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">kl_beta</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">epe</span> <span class="o">+</span> <span class="n">balanced_kl</span><span class="p">)</span>
        <span class="c1"># add regularization</span>
        <span class="n">loss_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">loss_weight</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">wd_coeffs</span><span class="p">[</span><span class="n">gstep</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wd_coeffs</span><span class="p">[</span><span class="n">gstep</span><span class="p">]</span> <span class="o">*</span> <span class="n">loss_w</span>
        <span class="n">cond_reg_spectral</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">lambda_norm</span> <span class="o">&gt;</span> <span class="mi">0</span> \
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">spectral_reg</span> <span class="ow">and</span> \
            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">spectral_norm</span>
        <span class="k">if</span> <span class="n">cond_reg_spectral</span><span class="p">:</span>
            <span class="n">loss_sr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">loss_spectral</span><span class="p">(</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wd_coeffs</span><span class="p">[</span><span class="n">gstep</span><span class="p">]</span> <span class="o">*</span> <span class="n">loss_sr</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loss_sr</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>80it [00:54,  1.48it/s]
80it [00:43,  1.84it/s]
80it [00:44,  1.78it/s]
80it [00:48,  1.65it/s]
80it [00:44,  1.79it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 3min 51s, sys: 6.77 s, total: 3min 58s
Wall time: 3min 55s
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># was with torch.linalg.vector_norm</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>80it [00:51,  1.54it/s]
80it [00:46,  1.72it/s]
80it [00:42,  1.88it/s]
80it [00:46,  1.73it/s]
80it [00:48,  1.63it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 3min 50s, sys: 8.81 s, total: 3min 59s
Wall time: 3min 56s
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">activities</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CPU</span><span class="p">,</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CUDA</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">kws</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">activities</span><span class="o">=</span><span class="n">activities</span><span class="p">,</span>
    <span class="n">record_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">with_stack</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="o">**</span><span class="n">kws</span><span class="p">)</span> <span class="k">as</span> <span class="n">prof</span><span class="p">:</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">epe</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">loss_recon</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">norm</span><span class="p">)</span>
    <span class="n">kl_all</span><span class="p">,</span> <span class="n">kl_diag</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">loss_kl</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
    <span class="c1"># balance kl</span>
    <span class="n">balanced_kl</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">kl_vals</span> <span class="o">=</span> <span class="n">kl_balancer</span><span class="p">(</span>
        <span class="n">kl_all</span><span class="o">=</span><span class="n">kl_all</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas</span><span class="p">,</span>
        <span class="n">coeff</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="p">[</span><span class="n">gstep</span><span class="p">],</span>
        <span class="n">beta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">kl_beta</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">epe</span> <span class="o">+</span> <span class="n">balanced_kl</span><span class="p">)</span>
    <span class="c1"># add regularization</span>
    <span class="n">loss_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">loss_weight</span><span class="p">()</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">wd_coeffs</span><span class="p">[</span><span class="n">gstep</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wd_coeffs</span><span class="p">[</span><span class="n">gstep</span><span class="p">]</span> <span class="o">*</span> <span class="n">loss_w</span>
    <span class="n">cond_reg_spectral</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">lambda_norm</span> <span class="o">&gt;</span> <span class="mi">0</span> \
        <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">spectral_reg</span> <span class="ow">and</span> \
        <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">spectral_norm</span>
    <span class="k">if</span> <span class="n">cond_reg_spectral</span><span class="p">:</span>
        <span class="n">loss_sr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">loss_spectral</span><span class="p">(</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wd_coeffs</span><span class="p">[</span><span class="n">gstep</span><span class="p">]</span> <span class="o">*</span> <span class="n">loss_sr</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">loss_sr</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">prof</span><span class="o">.</span><span class="n">key_averages</span><span class="p">(</span><span class="n">group_by_stack_n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">sort_by</span><span class="o">=</span><span class="s2">&quot;self_cuda_time_total&quot;</span><span class="p">,</span> <span class="n">row_limit</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">-------------------------------------------------------  ------------  ------------  
------------  ------------  ------------  ------------  ------------  ------------  
------------  ------------  
                                                   Name    Self CPU %      Self CPU   CPU 
total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg 
# of Calls  
-------------------------------------------------------  ------------  ------------  
------------  ------------  ------------  ------------  ------------  ------------  
------------  ------------  
                             aten::convolution_backward         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">5.90</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">56.</span>383ms        
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11.40</span>%     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">108.</span>907ms     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">310.</span>276us     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">208.</span>844ms        <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">49.17</span>%     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">218.</span>653ms     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">622.</span>943us   
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">351</span>  
                                aten::cudnn_convolution         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">5.00</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">47.</span>745ms         
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">7.45</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">71.</span>201ms     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">221.</span>810us      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">71.</span>497ms        <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">16.83</span>%     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">105.</span>171ms     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">327.</span>636us    
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">321</span>  
void cudnn::detail::dgrad_alg1_engine&lt;float, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">128</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">6</span>,<span style="color: #808000; text-decoration-color: #808000">...</span>         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.00</span>%       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.</span>000us         
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.00</span>%       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.</span>000us       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.</span>000us      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">63.</span>215ms        <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">14.88</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">63.</span>215ms       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">1.</span>054ms    
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">60</span>  
                                   volta_sgemm_64x64_nt         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.00</span>%       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.</span>000us         
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.00</span>%       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.</span>000us       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.</span>000us      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">46.</span>713ms        <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11.00</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">46.</span>713ms     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">126.</span>593us    
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">369</span>  
                                       cudaLaunchKernel        <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">26.61</span>%     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">254.</span>222ms        
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">26.61</span>%     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">254.</span>222ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">16.</span>282us      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">43.</span>567ms        <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">10.26</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">43.</span>567ms       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2.</span>790us   
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">15614</span>  
                                             aten::add_         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">3.54</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">33.</span>856ms         
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">6.90</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">65.</span>932ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">26.</span>205us      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">32.</span>449ms         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">7.64</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">34.</span>505ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">13.</span>714us    
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2516</span>  
void at::native::vectorized_elementwise_kernel&lt;<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">4</span>, at<span style="color: #808000; text-decoration-color: #808000">...</span>         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.00</span>%       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.</span>000us         
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.00</span>%       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.</span>000us       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.</span>000us      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">31.</span>880ms         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">7.51</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">31.</span>880ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">12.</span>468us    
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2557</span>  
void cudnn::winograd_nonfused::winogradForwardData4x<span style="color: #808000; text-decoration-color: #808000">...</span>         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.00</span>%       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.</span>000us         
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.00</span>%       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.</span>000us       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.</span>000us      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">31.</span>435ms         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">7.40</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">31.</span>435ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">85.</span>190us    
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">369</span>  
void cudnn::winograd_nonfused::winogradForwardOutput<span style="color: #808000; text-decoration-color: #808000">...</span>         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.00</span>%       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.</span>000us         
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.00</span>%       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.</span>000us       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.</span>000us      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">26.</span>804ms         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">6.31</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">26.</span>804ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">72.</span>640us    
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">369</span>  
                                              aten::mul         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">5.81</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">55.</span>523ms         
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">9.15</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">87.</span>372ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">37.</span>725us      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">21.</span>854ms         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">5.15</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">26.</span>911ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11.</span>620us    
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2316</span>  
-------------------------------------------------------  ------------  ------------  
------------  ------------  ------------  ------------  ------------  ------------  
------------  ------------  
Self CPU time total: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">955.</span>230ms
Self CUDA time total: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">424.</span>738ms

</pre>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">prof</span><span class="o">.</span><span class="n">key_averages</span><span class="p">(</span><span class="n">group_by_stack_n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">sort_by</span><span class="o">=</span><span class="s2">&quot;self_cpu_time_total&quot;</span><span class="p">,</span> <span class="n">row_limit</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">-------------------------------------------------------  ------------  ------------  
------------  ------------  ------------  ------------  ------------  ------------  
------------  ------------  
                                                   Name    Self CPU %      Self CPU   CPU 
total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg 
# of Calls  
-------------------------------------------------------  ------------  ------------  
------------  ------------  ------------  ------------  ------------  ------------  
------------  ------------  
                                       cudaLaunchKernel        <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">26.61</span>%     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">254.</span>222ms        
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">26.61</span>%     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">254.</span>222ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">16.</span>282us      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">43.</span>567ms        <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">10.26</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">43.</span>567ms       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2.</span>790us   
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">15614</span>  
                             aten::convolution_backward         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">5.90</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">56.</span>383ms        
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11.40</span>%     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">108.</span>907ms     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">310.</span>276us     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">208.</span>844ms        <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">49.17</span>%     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">218.</span>653ms     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">622.</span>943us   
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">351</span>  
                                              aten::mul         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">5.81</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">55.</span>523ms         
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">9.15</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">87.</span>372ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">37.</span>725us      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">21.</span>854ms         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">5.15</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">26.</span>911ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11.</span>620us    
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2316</span>  
                                aten::cudnn_convolution         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">5.00</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">47.</span>745ms         
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">7.45</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">71.</span>201ms     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">221.</span>810us      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">71.</span>497ms        <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">16.83</span>%     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">105.</span>171ms     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">327.</span>636us    
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">321</span>  
                                              aten::div         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">4.57</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">43.</span>701ms         
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">6.90</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">65.</span>879ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">39.</span>331us       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">6.</span>326ms         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">1.49</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">10.</span>167ms       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">6.</span>070us    
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">1675</span>  
                                             aten::add_         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">3.54</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">33.</span>856ms         
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">6.90</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">65.</span>932ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">26.</span>205us      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">32.</span>449ms         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">7.64</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">34.</span>505ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">13.</span>714us    
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2516</span>  
                                              aten::sum         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">3.28</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">31.</span>303ms         
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">4.86</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">46.</span>424ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">36.</span>962us      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">17.</span>573ms         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">4.14</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">17.</span>573ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">13.</span>991us    
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">1256</span>  
                                            aten::addmm         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2.97</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">28.</span>349ms         
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">4.38</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">41.</span>835ms     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">166.</span>012us       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">1.</span>517ms         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.36</span>%       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">4.</span>990ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">19.</span>802us    
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">252</span>  
                                              aten::add         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2.82</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">26.</span>940ms         
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">4.29</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">40.</span>992ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">51.</span>627us      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11.</span>840ms         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2.79</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">14.</span>414ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">18.</span>154us    
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">794</span>  
                                              aten::exp         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2.09</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">19.</span>971ms         
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">5.51</span>%      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">52.</span>658ms     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">180.</span>336us     <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">682.</span>000us         <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.16</span>%       <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">6.</span>437ms      <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">22.</span>045us    
<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">292</span>  
-------------------------------------------------------  ------------  ------------  
------------  ------------  ------------  ------------  ------------  ------------  
------------  ------------  
Self CPU time total: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">955.</span>230ms
Self CUDA time total: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">424.</span>738ms

</pre>
</div></div>
</div>
<section id="save-to-txt">
<h3>Save to txt?<a class="headerlink" href="#save-to-txt" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">prof</span><span class="o">.</span><span class="n">key_averages</span><span class="p">(</span><span class="n">group_by_stack_n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">sort_by</span><span class="o">=</span><span class="s2">&quot;self_cuda_time_total&quot;</span><span class="p">,</span> <span class="n">row_limit</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;profile_cuda.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    
<span class="n">output</span> <span class="o">=</span> <span class="n">prof</span><span class="o">.</span><span class="n">key_averages</span><span class="p">(</span><span class="n">group_by_stack_n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">sort_by</span><span class="o">=</span><span class="s2">&quot;self_cpu_time_total&quot;</span><span class="p">,</span> <span class="n">row_limit</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;profile_cpu.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Conclusion</strong>: jit was slowing things down</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">activities</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CPU</span><span class="p">,</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CUDA</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">kws</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">activities</span><span class="o">=</span><span class="n">activities</span><span class="p">,</span>
    <span class="n">record_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">with_stack</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="o">**</span><span class="n">kws</span><span class="p">)</span> <span class="k">as</span> <span class="n">prof</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">save</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch # 1, avg loss: 57.204149: 100%|██████████| 1/1 [02:20&lt;00:00, 140.16s/it]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">prof</span><span class="o">.</span><span class="n">key_averages</span><span class="p">(</span><span class="n">group_by_stack_n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">sort_by</span><span class="o">=</span><span class="s2">&quot;self_cuda_time_total&quot;</span><span class="p">,</span> <span class="n">row_limit</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;profile_cuda.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    
<span class="n">output</span> <span class="o">=</span> <span class="n">prof</span><span class="o">.</span><span class="n">key_averages</span><span class="p">(</span><span class="n">group_by_stack_n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">sort_by</span><span class="o">=</span><span class="s2">&quot;self_cpu_time_total&quot;</span><span class="p">,</span> <span class="n">row_limit</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;profile_cpu.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="compile">
<h2>Compile<a class="headerlink" href="#compile" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vae</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">(</span><span class="n">ConfigVAE</span><span class="p">(</span>
    <span class="n">n_latent_scales</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_groups_per_scale</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_latent_per_group</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
    <span class="n">scale_init</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">residual_kl</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ada_groups</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># separable=False,</span>
<span class="p">))</span>
<span class="n">tr</span> <span class="o">=</span> <span class="n">TrainerVAE</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">vae</span><span class="p">),</span>
    <span class="n">cfg</span><span class="o">=</span><span class="n">ConfigTrainVAE</span><span class="p">(</span>
        <span class="n">lr</span><span class="o">=</span><span class="mf">0.002</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">grad_clip</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">lambda_anneal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">lambda_init</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span> <span class="n">lambda_norm</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span>
        <span class="n">kl_beta</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">kl_anneal_cycles</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
        <span class="n">scheduler_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;T_max&#39;</span><span class="p">:</span> <span class="mf">660.0</span><span class="p">,</span> <span class="s1">&#39;eta_min&#39;</span><span class="p">:</span> <span class="mf">1e-05</span><span class="p">},</span>   
        <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adamax_fast&#39;</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">vae</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">total_latents</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>210
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="n">tr</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">tr</span><span class="o">.</span><span class="n">dl_trn</span><span class="p">)):</span>
        <span class="n">tr</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "2e51b5f6a2624475997333e7fe69fd90", "version_major": 2, "version_minor": 0}</script><div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/output_graph.py:670, in OutputGraph.call_user_compiler(self, gm)
    669 else:
--&gt; 670     compiled_fn = compiler_fn(gm, self.fake_example_inputs())
    671 _step_logger()(logging.INFO, f&quot;done compiler function {name}&quot;)

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/debug_utils.py:1055, in wrap_backend_debug.&lt;locals&gt;.debug_wrapper(gm, example_inputs, **kwargs)
   1054 else:
-&gt; 1055     compiled_gm = compiler_fn(gm, example_inputs)
   1057 return compiled_gm

File ~/anaconda3/lib/python3.8/site-packages/torch/__init__.py:1390, in _TorchCompileInductorWrapper.__call__(self, model_, inputs_)
   1388 from torch._inductor.compile_fx import compile_fx
-&gt; 1390 return compile_fx(model_, inputs_, config_patches=self.config)

File ~/anaconda3/lib/python3.8/site-packages/torch/_inductor/compile_fx.py:455, in compile_fx(model_, example_inputs_, inner_compile, config_patches)
    450 with overrides.patch_functions():
    451 
    452     # TODO: can add logging before/after the call to create_aot_dispatcher_function
    453     # in torch._functorch/aot_autograd.py::aot_module_simplified::aot_function_simplified::new_func
    454     # once torchdynamo is merged into pytorch
--&gt; 455     return aot_autograd(
    456         fw_compiler=fw_compiler,
    457         bw_compiler=bw_compiler,
    458         decompositions=select_decomp_table(),
    459         partition_fn=functools.partial(
    460             min_cut_rematerialization_partition, compiler=&quot;inductor&quot;
    461         ),
    462         keep_inference_input_mutations=True,
    463     )(model_, example_inputs_)

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/backends/common.py:48, in aot_autograd.&lt;locals&gt;.compiler_fn(gm, example_inputs)
     47 with enable_aot_logging():
---&gt; 48     cg = aot_module_simplified(gm, example_inputs, **kwargs)
     49     counters[&quot;aot_autograd&quot;][&quot;ok&quot;] += 1

File ~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:2805, in aot_module_simplified(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, hasher_type, static_argnums, keep_inference_input_mutations)
   2803 full_args.extend(args)
-&gt; 2805 compiled_fn = create_aot_dispatcher_function(
   2806     functional_call,
   2807     full_args,
   2808     aot_config,
   2809 )
   2811 # TODO: There is something deeply wrong here; compiled_fn running with
   2812 # the boxed calling convention, but aot_module_simplified somehow
   2813 # historically returned a function that was not the boxed calling
   2814 # convention.  This should get fixed...

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/utils.py:163, in dynamo_timed.&lt;locals&gt;.dynamo_timed_inner.&lt;locals&gt;.time_wrapper(*args, **kwargs)
    162 t0 = time.time()
--&gt; 163 r = func(*args, **kwargs)
    164 time_spent = time.time() - t0

File ~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:2498, in create_aot_dispatcher_function(flat_fn, flat_args, aot_config)
   2496 # You can put more passes here
-&gt; 2498 compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config)
   2500 if not hasattr(compiled_fn, &quot;_boxed_call&quot;):

File ~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:1713, in aot_wrapper_dedupe(flat_fn, flat_args, aot_config, compiler_fn)
   1712     if ok:
-&gt; 1713         return compiler_fn(flat_fn, leaf_flat_args, aot_config)
   1715 # Strategy 2: Duplicate specialize.
   1716 #
   1717 # In Haskell types, suppose you have:
   (...)
   1749 #   }
   1750 #   keep_arg_mask = [True, True, False, True]

File ~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:2087, in aot_dispatch_autograd(flat_fn, flat_args, aot_config)
   2086     flattened_joints, _ = pytree.tree_flatten(joint_inputs)
-&gt; 2087     fx_g = make_fx(joint_forward_backward, aot_config.decompositions)(
   2088         *joint_inputs
   2089     )
   2091 # There should be *NO* mutating ops in the graph at this point.

File ~/anaconda3/lib/python3.8/site-packages/torch/fx/experimental/proxy_tensor.py:714, in make_fx.&lt;locals&gt;.wrapped(*args)
    712 with decompose(decomposition_table), fake_tensor_mode, python_dispatcher_mode, \
    713      sym_mode, proxy_mode, disable_autocast_cache(), disable_proxy_modes_tracing(enable_current=True):
--&gt; 714     t = dispatch_trace(wrap_key(func, args, fx_tracer), tracer=fx_tracer, concrete_args=tuple(phs))
    716 # TODO: kind of a bad way to do it, should maybe figure out a better way

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:209, in _TorchDynamoContext.__call__.&lt;locals&gt;._fn(*args, **kwargs)
    208 try:
--&gt; 209     return fn(*args, **kwargs)
    210 finally:

File ~/anaconda3/lib/python3.8/site-packages/torch/fx/experimental/proxy_tensor.py:443, in dispatch_trace(root, tracer, concrete_args)
    438 def dispatch_trace(
    439         root: Union[torch.nn.Module, Callable],
    440         tracer: Tracer,
    441         concrete_args: Optional[Tuple[Any, ...]] = None,
    442 ) -&gt; GraphModule:
--&gt; 443     graph = tracer.trace(root, concrete_args)
    444     name = root.__class__.__name__ if isinstance(root, torch.nn.Module) else root.__name__

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:209, in _TorchDynamoContext.__call__.&lt;locals&gt;._fn(*args, **kwargs)
    208 try:
--&gt; 209     return fn(*args, **kwargs)
    210 finally:

File ~/anaconda3/lib/python3.8/site-packages/torch/fx/_symbolic_trace.py:778, in Tracer.trace(self, root, concrete_args)
    772         _autowrap_check(
    773             patcher, module.__dict__, self._autowrap_function_ids
    774         )
    775     self.create_node(
    776         &quot;output&quot;,
    777         &quot;output&quot;,
--&gt; 778         (self.create_arg(fn(*args)),),
    779         {},
    780         type_expr=fn.__annotations__.get(&quot;return&quot;, None),
    781     )
    783 self.submodule_paths = None

File ~/anaconda3/lib/python3.8/site-packages/torch/fx/_symbolic_trace.py:652, in Tracer.create_args_for_root.&lt;locals&gt;.flatten_fn(*args)
    651 tree_args = pytree.tree_unflatten(list(args), in_spec)
--&gt; 652 tree_out = root_fn(*tree_args)
    653 out_args, out_spec = pytree.tree_flatten(tree_out)

File ~/anaconda3/lib/python3.8/site-packages/torch/fx/experimental/proxy_tensor.py:459, in wrap_key.&lt;locals&gt;.wrapped(*proxies)
    457     track_tensor_tree(flat_tensors, flat_proxies, constant=None, tracer=tracer)
--&gt; 459 out = f(*tensors)
    460 out = pytree.tree_map_only(
    461     torch.Tensor,
    462     lambda t: get_proxy_slot(t, tracer, t, lambda x: x.proxy),
    463     out
    464 )

File ~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:1156, in create_forward_or_joint_functionalized.&lt;locals&gt;.traced_joint(primals, tangents)
   1155 def traced_joint(primals, tangents):
-&gt; 1156     return functionalized_f_helper(primals, tangents)

File ~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:1108, in create_forward_or_joint_functionalized.&lt;locals&gt;.functionalized_f_helper(primals, maybe_tangents)
   1106 try:
   1107     # Run the joint
-&gt; 1108     f_outs = flat_fn_no_input_mutations(fn, f_primals, f_tangents, meta, keep_input_mutations)
   1109 finally:

File ~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:1076, in flat_fn_no_input_mutations(fn, primals, maybe_tangents, meta, keep_input_mutations)
   1075     primals_after_cloning = primals
-&gt; 1076 outs = flat_fn_with_synthetic_bases_expanded(fn, primals, primals_after_cloning, maybe_tangents, meta, keep_input_mutations)
   1077 return outs

File ~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:1048, in flat_fn_with_synthetic_bases_expanded(fn, primals_before_cloning, primals_after_cloning, maybe_tangents, meta, keep_input_mutations)
   1047 assert len(meta.fw_metadata.input_info) == len(primals)
-&gt; 1048 outs = forward_or_joint(fn, primals_before_cloning, primals, maybe_tangents, meta, keep_input_mutations)
   1049 return outs

File ~/anaconda3/lib/python3.8/site-packages/torch/_functorch/aot_autograd.py:1017, in forward_or_joint(fn, primals_before_cloning, primals_after_cloning, maybe_tangents, meta, keep_input_mutations)
   1016     with fx_traceback.preserve_node_meta():
-&gt; 1017         backward_out = torch.autograd.grad(
   1018             needed_outs,
   1019             grad_primals,
   1020             grad_outputs=needed_tangents,
   1021             allow_unused=True,
   1022         )
   1023 backward_out_iter = iter(backward_out)

File ~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:269, in grad(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)
    268 if has_torch_function(overridable_args):
--&gt; 269     return handle_torch_function(
    270         grad,
    271         overridable_args,
    272         t_outputs,
    273         t_inputs,
    274         grad_outputs=grad_outputs,
    275         retain_graph=retain_graph,
    276         create_graph=create_graph,
    277         only_inputs=only_inputs,
    278         allow_unused=allow_unused,
    279         is_grads_batched=is_grads_batched,
    280     )
    282 if not only_inputs:

File ~/anaconda3/lib/python3.8/site-packages/torch/overrides.py:1534, in handle_torch_function(public_api, relevant_args, *args, **kwargs)
   1533 with _pop_mode_temporarily() as mode:
-&gt; 1534     result = mode.__torch_function__(public_api, types, args, kwargs)
   1535 if result is not NotImplemented:

File ~/anaconda3/lib/python3.8/site-packages/torch/_inductor/overrides.py:38, in AutogradMonkeypatch.__torch_function__(self, func, types, args, kwargs)
     37     return replacements[func](*args, **kwargs)
---&gt; 38 return func(*args, **kwargs)

File ~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:303, in grad(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)
    302 else:
--&gt; 303     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
    304         t_outputs, grad_outputs_, retain_graph, create_graph, t_inputs,
    305         allow_unused, accumulate_grad=False)

RuntimeError: Function ConvolutionBackward0 returned an invalid gradient at index 1 - expected device cuda:1 but got cuda:0

The above exception was the direct cause of the following exception:

BackendCompilerFailed                     Traceback (most recent call last)
File &lt;timed exec&gt;:5, in &lt;module&gt;

File ~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)
   1496 # If we don&#39;t have any hooks, we want to skip the rest of the logic in
   1497 # this function, and just call forward.
   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
   1499         or _global_backward_pre_hooks or _global_backward_hooks
   1500         or _global_forward_hooks or _global_forward_pre_hooks):
-&gt; 1501     return forward_call(*args, **kwargs)
   1502 # Do not call functions when jit is used
   1503 full_backward_hooks, non_full_backward_hooks = [], []

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:82, in OptimizedModule.forward(self, *args, **kwargs)
     81 def forward(self, *args, **kwargs):
---&gt; 82     return self.dynamo_ctx(self._orig_mod.forward)(*args, **kwargs)

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:209, in _TorchDynamoContext.__call__.&lt;locals&gt;._fn(*args, **kwargs)
    207 dynamic_ctx.__enter__()
    208 try:
--&gt; 209     return fn(*args, **kwargs)
    210 finally:
    211     set_eval_frame(prior)

File ~/Dropbox/git/_MTMST/model/vae2d.py:77, in VAE.forward(self, x)
     75 		latents.append(z)
     76 	# &#39;combiner_dec&#39;
---&gt; 77 	s = cell(s, self.expand[idx](z))
     78 	idx += 1
     79 else:

File ~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)
   1496 # If we don&#39;t have any hooks, we want to skip the rest of the logic in
   1497 # this function, and just call forward.
   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
   1499         or _global_backward_pre_hooks or _global_backward_hooks
   1500         or _global_forward_hooks or _global_forward_pre_hooks):
-&gt; 1501     return forward_call(*args, **kwargs)
   1502 # Do not call functions when jit is used
   1503 full_backward_hooks, non_full_backward_hooks = [], []

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:337, in catch_errors_wrapper.&lt;locals&gt;.catch_errors(frame, cache_size)
    334             return hijacked_callback(frame, cache_size, hooks)
    336 with compile_lock:
--&gt; 337     return callback(frame, cache_size, hooks)

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:404, in convert_frame.&lt;locals&gt;._convert_frame(frame, cache_size, hooks)
    402 counters[&quot;frames&quot;][&quot;total&quot;] += 1
    403 try:
--&gt; 404     result = inner_convert(frame, cache_size, hooks)
    405     counters[&quot;frames&quot;][&quot;ok&quot;] += 1
    406     return result

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:104, in wrap_convert_context.&lt;locals&gt;._fn(*args, **kwargs)
    102 torch.fx.graph_module._forward_from_src = fx_forward_from_src_skip_result
    103 try:
--&gt; 104     return fn(*args, **kwargs)
    105 finally:
    106     torch._C._set_grad_enabled(prior_grad_mode)

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:262, in convert_frame_assert.&lt;locals&gt;._convert_frame_assert(frame, cache_size, hooks)
    259 global initial_grad_state
    260 initial_grad_state = torch.is_grad_enabled()
--&gt; 262 return _compile(
    263     frame.f_code,
    264     frame.f_globals,
    265     frame.f_locals,
    266     frame.f_builtins,
    267     compiler_fn,
    268     one_graph,
    269     export,
    270     hooks,
    271     frame,
    272 )

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/utils.py:163, in dynamo_timed.&lt;locals&gt;.dynamo_timed_inner.&lt;locals&gt;.time_wrapper(*args, **kwargs)
    161     compilation_metrics[key] = []
    162 t0 = time.time()
--&gt; 163 r = func(*args, **kwargs)
    164 time_spent = time.time() - t0
    165 # print(f&quot;Dynamo timer: key={key}, latency={latency:.2f} sec&quot;)

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:324, in _compile(code, globals, locals, builtins, compiler_fn, one_graph, export, hooks, frame)
    322 for attempt in itertools.count():
    323     try:
--&gt; 324         out_code = transform_code_object(code, transform)
    325         orig_code_map[out_code] = code
    326         break

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/bytecode_transformation.py:445, in transform_code_object(code, transformations, safe)
    442 instructions = cleaned_instructions(code, safe)
    443 propagate_line_nums(instructions)
--&gt; 445 transformations(instructions, code_options)
    446 return clean_and_assemble_instructions(instructions, keys, code_options)[1]

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:311, in _compile.&lt;locals&gt;.transform(instructions, code_options)
    298 nonlocal output
    299 tracer = InstructionTranslator(
    300     instructions,
    301     code,
   (...)
    309     mutated_closure_cell_contents,
    310 )
--&gt; 311 tracer.run()
    312 output = tracer.output
    313 assert output is not None

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py:1726, in InstructionTranslator.run(self)
   1724 def run(self):
   1725     _step_logger()(logging.INFO, f&quot;torchdynamo start tracing {self.f_code.co_name}&quot;)
-&gt; 1726     super().run()

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py:576, in InstructionTranslatorBase.run(self)
    571 try:
    572     self.output.push_tx(self)
    573     while (
    574         self.instruction_pointer is not None
    575         and not self.output.should_exit
--&gt; 576         and self.step()
    577     ):
    578         pass
    579 except BackendCompilerFailed:

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py:540, in InstructionTranslatorBase.step(self)
    538     if not hasattr(self, inst.opname):
    539         unimplemented(f&quot;missing: {inst.opname}&quot;)
--&gt; 540     getattr(self, inst.opname)(inst)
    542     return inst.opname != &quot;RETURN_VALUE&quot;
    543 except BackendCompilerFailed:

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py:1792, in InstructionTranslator.RETURN_VALUE(self, inst)
   1787 _step_logger()(
   1788     logging.INFO,
   1789     f&quot;torchdynamo done tracing {self.f_code.co_name} (RETURN_VALUE)&quot;,
   1790 )
   1791 log.debug(&quot;RETURN_VALUE triggered compile&quot;)
-&gt; 1792 self.output.compile_subgraph(
   1793     self, reason=GraphCompileReason(&quot;return_value&quot;, [self.frame_summary()])
   1794 )
   1795 self.output.add_output_instructions([create_instruction(&quot;RETURN_VALUE&quot;)])

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/output_graph.py:541, in OutputGraph.compile_subgraph(self, tx, partial_convert, reason)
    538 output = []
    539 if count_calls(self.graph) != 0 or len(pass2.graph_outputs) != 0:
    540     output.extend(
--&gt; 541         self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)
    542     )
    544     if len(pass2.graph_outputs) != 0:
    545         output.append(pass2.create_store(graph_output_var))

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/output_graph.py:588, in OutputGraph.compile_and_call_fx_graph(self, tx, rv, root)
    586 assert_no_fake_params_or_buffers(gm)
    587 with tracing(self.tracing_context):
--&gt; 588     compiled_fn = self.call_user_compiler(gm)
    589 compiled_fn = disable(compiled_fn)
    591 counters[&quot;stats&quot;][&quot;unique_graphs&quot;] += 1

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/utils.py:163, in dynamo_timed.&lt;locals&gt;.dynamo_timed_inner.&lt;locals&gt;.time_wrapper(*args, **kwargs)
    161     compilation_metrics[key] = []
    162 t0 = time.time()
--&gt; 163 r = func(*args, **kwargs)
    164 time_spent = time.time() - t0
    165 # print(f&quot;Dynamo timer: key={key}, latency={latency:.2f} sec&quot;)

File ~/anaconda3/lib/python3.8/site-packages/torch/_dynamo/output_graph.py:675, in OutputGraph.call_user_compiler(self, gm)
    673 except Exception as e:
    674     compiled_fn = gm.forward
--&gt; 675     raise BackendCompilerFailed(self.compiler_fn, e) from e
    676 return compiled_fn

BackendCompilerFailed: debug_wrapper raised RuntimeError: Function ConvolutionBackward0 returned an invalid gradient at index 1 - expected device cuda:1 but got cuda:0

Set torch._dynamo.config.verbose=True for more information


You can suppress this exception and fall back to eager by setting:
    torch._dynamo.config.suppress_errors = True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tr</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">comment</span><span class="o">=</span><span class="s1">&#39;compiled_test&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./nb/2023-04"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="04_dan.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">(04) Dan notebook</p>
      </div>
    </a>
    <a class="right-next"
       href="06_sim-kNN.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">(06) Sim – kNN analysis</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trainer">Trainer</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#save-to-txt">Save to txt?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compile">Compile</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Hadi Vafaii
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>